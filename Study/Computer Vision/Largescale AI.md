## Modeling : domain knowledge
Feature Learning + Classification
목적성이 불분명하지만 데이터 셋을 학습하면서 의미를 찾음
### Data : labeling
어떻게 효율적이고 고품질의 데이터셋을 만들것인가

AI가 푸려고 하는 문제가 빠르게 변함
학습의 의미가 빠르게 변함
사용자를 고려해서 미리 예측하는 것이 쉽지않음 - 모두 고려하기 위해서는 학습과 시간과 비용이 너무 많이 소요됨
#### ImageNet
120만장 라벨링..
##### COYO-Dataset

#### Large-Scale
사람이 라벨링하지 않는다.
의미를 어떻게 추출할 것이냐
대량의 데이터를 기계적으로 돌림

##### Image-Text Pair
이미지와 description (관련성 검사 filtering)

##### CLIP
이미지 -> 텍스트

##### Unclip
텍스트 -> 이미지
Dalle, stable diffusion

## AI : Large Language Model (GPT-style)
거대 언어 모델 - 상당히 단순하다.
다음 단어가 뭐야 -> 말하는 법을 배웠다. -> 말하는 것 이상으로 할 수 있는 것이 많았다.

### GPT-3
LLM
다음 단어 예측 - 5000억개 정도 데이터셋 학습
task description , example , prompt

초기에 일반 사용자들이 원활하게 쓰는 것은 어려웠다.
프롬프트 엔지니어링 - 

### ChatGPT
Conversational Model
대화하는 법을 학습함.

## Q&A
오타를 인식하고 문제를 풀기도 함
의도적으로 동일한 패턴으로 오타를 내는 방식으로 학습

AI 연구자 엔지니어가 필요한 소양과 역량?
직접해봐라

이미지 데이터셋 - 라벨링을 인공지능이 한다.
언어모델, 이미지모델 - 다양한 분포 - 필터링을 하지 않는 이유 - 사회적 양상이나 가치가 늘 변하기 때문에 , 정말 위험한 것들만

실제 업무에서 논문이나 연구를 어떻게 관리하는가?
논문이 쏟아져나오는데 다 읽을 필요는 없다.
대표되는 논문들만 follow up, 세미나 진행
본인의 관심사가 분명한 것이 도움이 됨 - 일이관지

ChatGPT - 향후 미래 발전 방향

AI의 답이 다시 피드백으로 학습 - 선순환으로 예측

