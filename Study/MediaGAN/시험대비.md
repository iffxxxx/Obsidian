# MediaGAN_김희원 교수님

## 프로젝트
### 문제 정의
뇌졸중은 매우 흔한 질환으로 6명중 1명은 뇌졸중을 앓는다고 알려져 있습니다. 또한 우리나라에서 주된 사망원인 중 하나입니다. 뇌졸중은 다양한 원인에 따라 발생하며, 뇌졸중의 원인에 따라 치료가 다르게 됩니다. 뇌졸중 중 대부분을 차지하는 뇌경색은 뇌혈관이 막힘에 따라 발생하며, 이에 따른 검사시간 및 비용이 필요하게 됩니다. 따라서 저희 프로젝트에서는 **뇌졸중 환자의 MRI 스캔 이미지를 기반으로 한 데이터셋으로 인공 신경망 네트워크를 활용하여 뇌 조직, 혈관, 출혈 등의 주요 부위를 정확하게 식별하고 분할하는 방법**을 개발하려고 합니다. 이를 위한 데이터로 BraTS의 2013 데이터로 총 50명의 T1, T2, FLAIR, post-Gadolinium T1으로 4가지의 MRI가 제공되었습니다. 이를 통해 해결할 것은 lesion segmentation이고 label로는 "부종", "조양”이나 “비정상적인 조직 성장", "종양의 성장 활동이 느린 종양의 중심 부분", "죽은 뇌 조직" 네 가지가 주어졌습니다.
### 해당 문제에 대한 일반적인 접근법
해당 문제인 lesion segmentation의 해결에는 컴퓨터 비전 분야 중 하나인 **image segmentation**을 사용합니다. 이미지에서 픽셀 또는 픽셀 그룹을 서로 다른 객체 또는 영역으로 분할하는 작업을 의미하는데, 이를 통해 이미지 내의 객체를 정확하게 식별하고 분리할 수 있습니다. 여기서 사용할 **UNET은 이미지 세그멘테이션 작업에 주로 사용되는 딥러닝 아키텍처 중 하나**입니다. UNet은 원본 이미지와 동일한 크기의 세그멘테이션 맵을 출력하는 컨볼루션 신경망 구조로, 영상에서 다양한 객체 또는 영역을 정확하게 식별하는 데 뛰어난 성능을 보입니다. UNet은 이미지에서 세그멘테이션 맵을 생성하기 위해 인코더와 디코더 부분으로 구성되며, 다양한 이미지 세그멘테이션 작업에 적용할 수 있습니다. UNet 아키텍처의 특징은 작은 객체나 디테일한 부분도 잘 분할할 수 있다는 것입니다.
### 일반적인 접근법의 제한 사항 (from 논문 or 본인 생각)
하지만 UNET 논문에 제시 되어있는 사항들을 그대로 적용 시 성능이 기존에 UNET의 등장하지 않았던 대회의 상위권 수상자들의 성적과 비교하여도 더 낮게 나왔습니다. 이러한 문제점은 BraTS에서 제공한 2013 데이터의 특성으로 인한 것으로 판단이 됩니다. **뇌 MRI 데이터는 뇌종양의 다양성, 데이터 특이성 등을 갖고 있어서 다른 의료 응용 분야와는 다른 데이터 특성**을 가집니다. 이러한 데이터 특이성은 UNET과 같은 모델을 적용할 때 성능에 영향을 미칠 수 있습니다. 기존의 논문에서 제시한 데이터 증강 방식 및 전처리 과정이 T1, T2, FLAIR, post-Gadolinium T1의 4가지 mri에 부합하지 않았습니다. 이러한 문제가 mri 특유의 데이터 특이성 때문에 성적이 오히려 낮게 나오는 걸로 판단하였습니다.
### 제한 사항에 대한 해결 방안 (from 논문 or 본인 생각)
이러한 해결방안으로 기존의 상위권 BraTS 2013 데이터셋 기반으로 한 다른 두가지 논문의 데이터 pre-processing 과정을 적용시키려고 합니다. “Brain tumor segmentation with Deep Neural Networks”와 “Brain Tumor Segmentation Using Convolutional Neural Networks in MRI Images”이 두 논문 또한 UNET을 활용하지 않은 네트워크 레이어를 쌓아서 개발한 것으로 이 논문의 **데이터 전처리 과정에는 뇌 MRI 데이터는 다중 모달리티, 뇌종양의 다양성, 데이터 특이성 등을 고려하고 이에 적합한 전처리**에 대해서 설명하고 있습니다. 이러한 전처리 방식은 데이터의 특이성 문제를 해결할 수 있고, 최근 연구 트렌드를 읽으며 효과적인 의료 MRI 영상 image segmentation 인공지능 모델들을 도합하여 효과적인 네트워크로 MRI 이미지의 lesion segmentation 과제를 적합하게 해결해 나가고 있습니다.

## 선형분류기
### 문제 정의_파라미터 조정
선형 분류기는 이미지를 선형식으로 나타낸 후 분류하는 기법이다. 이미지는 픽셀별 숫자의 형태, 즉 행렬의 형태로 나타나는데, 이 행렬의 특성을 이용하여 가중치 w와 편향값 b를 추가하여 선형식으로 변환하는 것이다. 이미지의 행렬값을 하나의 열로 쭉 편 후, 가중치를 곱해주고 편향값을 더해주면 됩니다. 선형 분류기는 **선형성(linearity)으로 인해 분류 결과**가 달라질 가능성이 있습니다. 따라서 좋은 결과를 얻기 위해서는 **적절한 가중치와 편향을 조정**하여 예측 값과 실제 값의 오차를 최소화하는 방향으로 사용해야 합니다. 선형 분류기는 일반적으로 손실 함수를 통하여 예측 값과 실제 값의 차이를 최소화하면서 자신의 파라미터를 검증합니다. 그러나 수작업으로 이러한 파라미터를 조정하는 것에는 한계가 있습니다.
### 해당 문제에 대한 일반적인 접근법_경사 하강법
[출처](https://hi-guten-tag.tistory.com/205)
이 과정에서 사용되는 것이 **경사 하강법(Gradient Descent)** 입니다. 경사하강법은 현재 위치의 기울기가 음수라면 파라미터를 증가시켜 최솟값을 찾을 수 있습니다. 반대로 기울기가 양수라면 파라미터를 감소시키면 최솟값을 찾을 수 있습니다. 즉 미분과 다르게 **반복적으로 파라미터를 업데이트 하면서 최적화 과정을 진행**하므로 모델을 업데이트하는데 필요한 그래디언트(기울기) 정보를 효과적으로 얻을 수 있습니다. 경사하강법은 통상적으로 학습률과 기울기 정보를 혼합하여 내가 나아갈 방향과 거리를 결정합니다. 따라서 적절한 학습률(Learning Rate)를 조절하는 Scheduling 기법이 필요합니다. 또한 지역 최솟값에 수렴할 수 있는 가능성이 존재합니다. 기울기의 지수 가중 이동 평균을 사용하여 가중치를 업데이트하는 Adam 옵티마이저를 사용하여 학습률을 자동으로 조정하고, 전역 최소값을 찾을 수 있습니다.
### 일반적인 접근법의 제한 사항_비선형형
선형 분류기에 Adam 옵티마이저를 사용하더라도, 모델 자체는 여전히 선형입니다. 입력 특성과 가중치 간의 선형 관계를 학습하기에 결정 경계도 직선 또는 초평면으로 표현됩니다. XOR 분류와 같이 비선형 분류를 선형 분류로 해결하기에는 제한이 있습니다. 모델 아키텍처 자체를 변경하지 않는 한 비선형 패턴을 처리하기는 힘듭니다. 특히 **이미지 데이터에는 텍스처, 엣지, 색상 및 공간적인 구조와 같은 다양한 비선형 특징이 포함**되어 있습니다. 이미지 데이터와 같이 복잡한 비선형 특징을 가진 경우, 선형 분류기로는 복잡한 특징을 충분히 모델링하기 어려울 수 있습니다. 

### 제한 사항에 대한 해결 방안_신경망
[출처](https://velog.io/@recoder/%EB%94%A5%EB%9F%AC%EB%8B%9D-%ED%95%99%EC%8A%B5%EB%B0%A9%EB%B2%95-%EA%B8%B0%EB%B3%B8-%EC%9B%90%EB%A6%AC-%EC%8B%A0%EA%B2%BD%EB%A7%9D-%EC%9D%B4%EB%A1%A0)
이러한 제한 사항에 대한 해결 방법으로 비선형성을 추가한 **신경망**(**Neural Network**)이 있습니다. 비선형 활성화 함수를 사용한 신경망은 복잡한 패턴을 학습할 수 있도록 입력 데이터를 변환합니다. 이 비선형성을 활용하여 다층 신경망(Multi-Layer Perceptron, MLP)을 구성합니다. MLP는 노드 수를 증가시켜 정확성을 높일 수 있지만 속도가 느려집니다. 따라서 층을 깊게 쌓음으로써 층별 노드 수를 줄일 수 있으며, 이로써 속도를 빠르게 만들 수 있습니다. 깊게 쌓인 은닉층은 입력층과 출력층 사이에 위치하며 중간 계산을 수행합니다. 각 은닉층은 입력 데이터를 받아 가중치와 활성화 함수를 사용하여 새로운 표현을 생성합니다. 이를 통해 다양한 수준의 추상적인 특징을 학습할 수 있습니다. 다층 구조를 사용함으로써 비선형성을 계층적으로 적용할 수 있습니다. 각 은닉층을 통과할 때마다 데이터는 더 복잡한 비선형 표현으로 변환되며, 이는 복잡한 패턴 및 특징을 학습하는 데 도움이 됩니다.
## 과적합_수연
### 문제 정의_일반화 성능 향상
카메라 앱의 얼굴 인식 기능이 특정 조명과 각도에서만 잘 작동하고, 그 외의 조건에서는 제대로 인식하지 못하는 경우가 있습니다. 이러한 문제는 얼굴을 인식하는 머신러닝 모델의 과적합 때문일 수 있습니다. **과적합은 모델이 훈련 데이터에 지나치게 최적화되는 현상**을 말한다. 이로 인해 모델은 훈련 데이터에는 높은 성능을 보이지만, 새로운 데이터에는 예측 능력이 떨어집니다. 이러한 현상은 데이터의 수가 적은 데 비해 노이즈 데이터라고 하는 관련 없는 정보가 많거나, 문제를 해결하기 위해 필요한 데이터가 적은 경우에 발생합니다. 과적합된 모델은 특징 공간의 차원이 높은 경우, 다항식의 차수가 높은 경우에 나타나며, 심지어 노이즈나 무작위한 변동까지 학습하는 경우에 발생할 수 있다. 과적합을 진단하기 위해선 **학습오차와 시험오차의 차이인 일반화 오차**를 보면 된다. 일반화 오차는 모델이 새로운 데이터에 얼마나 잘 동작하는지를 측정하는 지표로, 과적합시 높아진다. 교차검증은 모델의 일반화 성능을 평가하는데 유용하며 과적합을 감지하는 데에도 적용할 수 있다. **모델의 일반화 성능능 향상**을 위해 과적합을 해결해야 합니다.
### 해당 문제에 대한 일반적인 접근법_정규화, 하이퍼파라미터
과적합을 해결하기 위한 방법으로 **정규화**와 **하이퍼파라미터 조정**을 할 수 있다. 정규화의 주요 목적은 모델의 복잡도를 제한하면서도 데이터의 주요 특성을 잡아내는 것이다. 이 기법은 모델의 가중치에 특정 제약을 가해 복잡한 모델이 데이터의 잡음까지 학습하는 것을 방지한다. 하이퍼 파라미터는 알고리즘의 동작을 제어하는 변수로, 여기에는 **학습률, 정규화의 강도, 트리의 깊이 등 다양한 요소가 포함**됩니다. 이러한 하이퍼파라미터를 잘못 설정하면 모델의 성능이 크게 저하될 수 있기 때문에 최적값을 찾는 것이 중요합니다. 따라서 교차 검증을 통해 다양한 파라미터 조합을 시도하며 최적의 값을 찾습니다. 이렇게 하여, 모델이 훈련 데이터에만 특화되지 않고 일반화된 성능을 보이도록 할 수 있습니다. 결론적으로, 정규화와 하이퍼파라미터 조정은 훈련 오차와 검증 오차 사이의 간격이 줄어들게 되어 모델의 일반화 성능이 향상될 수 있습니다.
### 일반적인 접근법의 제한 사항_훈련 데이터 부족
정규화와 하이퍼파라미터 조정은 과적합을 완화하는 효과적인 기법입니다. 그러나 **훈련 데이터가 부족**할 때에는 이런 방법만으로 과적합 문제를 완전히 해결하는 것은 어렵습니다. 이는 정규화와 하이퍼파라미터 조정이 주로 모델의 복잡도를 제한하는 데 중점을 둔 방식이기 때문에 데이터 부족의 문제를 해결하지 못한다. 훈련 데이터가 적을 경우, **모델은 특정 패턴이나 노이즈에 과도하게 반응**하게 되어 과적합의 위험이 커진다. 이때 **너무 강한 정규화를 적용하면, 모델은 필요한 표현력을 잃어 과소적합**(Underfitting)으로 이어질 수 있다. 따라서, 훈련 데이터가 부족한 상황에서는 정규화와 하이퍼파라미터 조정 외의 다양한 방법도 함께 고려해야 한다.
### 제한 사항에 대한 해결 방안
이러한 제한사항을 극복하기 위해 **데이터 증강 기법**을 활용할 수 있다. 데이터 증강은 기존 데이터에 약간의 변형을 가해 새로운 형태의 데이터를 생성하는 방식이다. 이 방법을 통해 모델이 다양한 조건과 상황에 대응할 수 있게 되어, 제한된 훈련 데이터 내에서의 과적합을 줄일 수 있다. 특히 이미지 데이터에서는 **회전, 반전, 확대, 축소와 같은 기법을 활용해 데이터의 다양성을 향상**시킬 수 있다. 하지만 과도한 변형은 데이터가 실제 상황과 다르게 표현될 위험이 있으므로, 증강 기법을 적용할 때는 원래 데이터의 특성을 유지하는 범위 내에서 조정해야 한다. 이렇게 증강된 데이터를 통해 모델은 다양한 변화에도 유연하게 대응할 능력을 키울 수 있으며, 이는 모델의 일반화 능력을 상승시키는 데 크게 도움을 준다.
## 과적합_지훈
### 문제 정의
과적합(Overfitting)은 기계 학습 및 통계 모델링에서 흔히 나타나는 문제로, 기계 학습 모델이 학습 데이터에 대한 정확한 예측을 제공하지만 새 데이터에 대해서는 제공하지 않을 때 발생하는 바람직하지 않은 기계 학습 동작입니다. 이 모델은 훈련 데이터를 외우는 것으로 제한되며 일반화가 부족합니다. 그렇기 때문에 이 모델은 새로운, 이전에 본 적 없는 데이터에 대한 예측 능력이 낮아집니다. 이러한 현상은 데이터의 수가 적은 데 비해 노이즈 데이터라고 하는 관련 없는 정보가 많거나, 문제를 해결하기 위해 필요한 데이터가 적은 경우에 발생합니다. 과적합된 모델은 종종 많은 매개변수와 특성을 사용하며, 심지어 노이즈나 무작위한 변동까지 학습합니다. 이는 실제 문제에 비해 과도하게 복잡한 모델을 생성하는 특징입니다. 이러한 복잡한 모델은 종종 인공 신경망에서 은닉층의 수나 매개변수의 수가 과도하게 높은 경우에 나타납니다.

### 해당 문제에 대한 일반적인 접근법
일반적으로 overfitting을 대응하기 위해서는 과적합의 원인을 제거하는 방식으로 대응합니다. 즉, 두 가지 주요 해결 방법은 더 많은 데이터를 수집하거나 모델의 복잡도를 줄이는 것입니다. 첫 번째 해결 방법인 더 많은 데이터 수집은 결국 학습 데이터의 다양성을 늘리는 것을 의미하며, 이로써 모델은 더 많은 훈련 데이터를 통해 일반화를 강화하고, 기본 패턴과 관련된 정보를 학습하여 데이터의 잡음이나 무작위 변동을 포착하지 않도록 도움을 줍니다. 특성(Features)을 줄이는 방법은 일반적으로 두 가지로 나눌 수 있습니다. 첫 번째 방법은 사람이 수동적으로 특성을 선택하거나 제거하는 방법이며, 두 번째 방법은 모델이 자체적으로 최적의 특성을 선택하거나 가중치를 부여하는 방법입니다.
### 일반적인 접근법의 제한 사항 (from 논문 or 본인 생각)
하지만 과적합의 원인을 제거하는 방법에는 제한사항 존재합니다. 당연히 데이터를 늘리는 것은 단순하지만 정확한 해결법이지만 실질적으로 데이터를 더 수집하여 수를 늘리는 방법은 대부분의 경우에 적용하기 어렵습니다. 인공 신경망의 복잡도를 줄이는 방법 즉, 은닉층의 수나 매개변수의 수를 선택하는 방법 또한 실제로 사람이 수동적으로 줄여가며 진행하기엔 시간과 자원이 많이 들고, 모델이 자체적으로 선택하는 방법 또한 모델의 구조를 변경하기에 최적의 해결책을 확신하기 어렵습니다.
### 제한 사항에 대한 해결 방안 (from 논문 or 본인 생각)
이러한 제한 사항에 대한 해결 방법은 모델에 제약을 가하는 규제를 적용하여 그 영향력을 조정하는 것입니다. 규제는 손실함수에 가중치의 노름(norm)을 더한 함수를 목적 함수(Objective function)로 설정하여 가중치를 제한합니다. 대표적인 방법으론 L1, L2 규제가 존재합니다. 이 두가지 방법은 모두 특정 가중치가 클수록 더 큰 패널티를 부여하여 해당 input에 대해 지나치게 fit하지 않도록 조절하는 것입니다. 두번째 방법으로는 Dropout 방법이 있습니다. Drop out이란 모델의 뉴런을 임의로 삭제하면서 학습하는 방법입니다. 학습시 무작위의 은닉층의 뉴런을 골라 배제하고, 다음 layer로 신호가 전달되지 못하도록 하는 것 입니다. 이는 더욱 편향되지 않은 출력값을 얻는 데 효과적이며 훨씬 더 적은 계산 비용이 든다는 장점 또한 존재합니다. 또한 기존의 모델의 파라미터 축소와 달리 파라미터의 크기를 제한함으로써 모델 구조를 변경하지 않습니다.

## 합성곱_신경망_민수
### 문제 정의
기존에 DNN을 통해 이미지를 분류하려 하였으나 DNN은 이미지 데이터를 1차원으로 flatten하여 사용하기에 파라미터의 수가 지나치게 많아지는 한계가 있었습니다. 그리고 이미지에서 특정 위치에 있는 픽셀들은 그 주변에 있는 일부 픽셀들과만 상관 관계가 높을 뿐이며 거리가 멀어지면 멀어질수록 그 영향은 감소하게 됩니다. 이미지에는 이러한 공간적/지역적 정보가 존재하기 때문에 이미지 데이터를 그대로 보존해야 합니다. 즉, DNN에서 이미지 데이터를 flatten하면 각 데이터의 공간적/지역적 정보가 손실되게 됩니다. 이러한 문제를 해결하기 위해 CNN이라는 방법을 사용하기 시작했습니다. CNN은 기존의 Neural Network에서 Convolution이라는 전처리 작업이 들어간 모델입니다. 이지지를 raw input 그대로 받음으로써 공간적/지역적 정보를 유지한 채 feature들의 계층을 빌드업합니다. CNN의 중요 포인트는 이미지 전체보다는 부분을 보는 것, 그리고 이미지의 한 픽셀과 주변 픽셀들의 연관성을 살리는 것입니다.

### 해당 문제에 대한 일반적인 접근법
CNN은 이미지의 특징을 추출하는 부분과 클래스를 분류하는 부분으로 나눌 수 있습니다. 특징 추출은 Convolution Layer와 Pooling Layer를 여러 겹 쌓는 형태로 구성됩니다. Convolution Layer는 입력 데이터에 필터를 적용 후 활성화 함수를 반영하는 필수 요소이고, Pooling Layer는 선택적인 부분입니다. 이미지 분류에서는 분류를 위해 Fully Connected Layer를 추가합니다. Fully Connected Layer에 사용하기 위해 특징을 추출하는 부분과 분류하는 부분 사이에 이미지 데이터를 배열 형태로 만드는 Flatten 레이어가 위치합니다. Convolution Layer에서 사용하는 필터는 입력값 이미지의 모든 영역에 반복 적용을 하여 각 행렬 간에 Inner product를 사용하여 중요한 특징을 살리고 크기를 줄인 새로운 데이터로 결과값을 도출합니다. 이전의 결과값을 그대로 Fully Connected layer로 적용하면 연산량이 기하급수적으로 늘어나기에 Pooling Layer를 통해서 크기를 줄이고 특정 feature를 강조합니다. 이후 Fully Connected Layer를 적용하고 Softmax 활성화 함수를 적용하여 최종 결과물을 출력합니다.

### 일반적인 접근법의 제한 사항 (from 논문 or 본인 생각)
앞서 말했듯, CNN은 Convolution Layer와 Pooling Layer를 여러 겹 쌓기 때문에 신경망이 깊어집니다. 데이터를 그대로 보존하여 특성을 살리는 CNN 기법은 이론적으로 훌륭하나, 이렇게 깊어진 신경망은 **내부 공변량 변화**가 발생하여 학습이 어렵습니다. 내부 공변량 변화는 깊은 신경망에서 학습이 여러 번 진행되면서 첫번째 층의 매개변수가 변화함에 따라 분포가 달라지고 바뀐 분포가 다음층으로 넘어가며 입력 데이터의 분포가 변하는 현상을 말합니다. 이러한 변화는 학습을 방해하는 요인으로 작용됩니다. 또한 내부 공변량 변화가 발생하여 층마다 입력의 분포가 달라지며 역전파 과정에서 기울기 소실 또는 폭주의 문제가 발생할 수 있습니다.

### 제한 사항에 대한 해결 방안 (from 논문 or 본인 생각)
위의 문제들을 해결하기 위해서는 입력의 분포를 안정화하고, 층 간의 상호 작용을 원활하게 해야 합니다. 이를 활성화 함수로 선형 함수를 사용하게 되면 층을 깊게 쌓을 때의 이점이 사라집니다. 그렇기 때문에 새로운 방식을 찾던 중 각 층의 입력을 정규화 해야 한다는 의견이 나왔습니다. 이러한 관점에서 탄생한 방법이 배치 정규화입니다. 배치 정규화는 각 미니배치의 입력을  정규화합니다. 학습 시 배치 단위의 평균과 분산을 차례대로 받아 이동 평균과 이동 분산을 저장해놓았다가 테스트할 때는 해당 배치의 평균과 분산을 구하지 않고 저장해둔 평균과 분산으로 정규화를 합니다. 이러한 과정을 통해 모든 층의 가중치를 동일한 scale로 만들어서 입력의 분포를 안정화 시킬 수 있습니다. 그렇기 때문에 가중치 초기화에 덜 민감해져서 깊은 신경망의 학습을 안정적으로 만들 수 있습니다.

## 합성곱 신경망_은재
### 세부 문제 정의
CNN은 합성곱 연산을 사용하여 **작은 필터(커널)을 이미지 위를 슬라이딩 하며 각 위치에서 필터와 이미지의 일부를 곱하여 특징 맵을 생성**합니다. 이 과정은 이미지 내에서 다양한 패턴과 특징을 탐지하는 데 사용합니다. 그러나 합성곱 연산에는 몇 가지 단점이 있습니다. 합성곱 연산은 많은 수의 곱셈과 덧셈을 수반하므로 **계산 비용**이 높을 수 있습니다. 이미지와 필터 크기가 크고, 채널 수가 많은 경우 연산 부하가 더 증가합니다. 또한 합성곱 연산은 입력 이미지의 원래 크기와 위치 정보를 그대로 유지하지 않습니다. 즉, 입력 이미지를 거치면서 **이미지의 픽셀 위치나 크기에 대한 정보가 일부 손실**될 수 있습니다 이로 인해 모델이 객체의 정확한 위치나 크기를 정확하게 파악하는 데 어려움이 있을 수 있으며, 이는 객체 검출 및 위치 추정 작업에서 문제가 될 수 있습니다.
### 해당 문제에 대한 일반적인 접근법
**풀링**은 합성곱 신경망(CNN)에서 주로 사용되는 과정으로, 주로 합성곱 연산의 결과인 특징 맵을 처리하는 단계입니다. 풀링은 **입력 이미지 또는 특징 맵의 공간 차원을 축소하는 역할**을 합니다. 이것은 연산량을 줄이고 모델의 계산 비용을 낮추는 데 도움을 줍니다. 작은 차원의 특징 맵으로 작업하기 때문에 **모델의 복잡성을 관리하고 효율성을 높입니다.** 또한 풀링은 이미지의 특징을 효과적으로 **계층화**해줍니다. 풀링은 CNN에서 여러번 사용되며, 이로 인해 모델은 계층적인 특징 추출을 수행하게 됩니다. 처음에는 작은 특징을 추출하고, 이러한 작은 특징을 결합하여 더 큰 패턴과 특징을 학습할 수 있습니다. 이러한 계층화는 모델이 **다양한 추상화 수준에서 이미지 정보를 이해하고 해석하는데 도움**이 됩니다. 그 중 **최대 풀링**은 각 풀링 영역에서 **최댓값을 선택하여 중요한 정보를 유지**합니다. 이것은 작은 위치 이동에 대한 불변성을 제공하고, 모델이 객체의 위치가 약간 변해도 해당 객체를 인식할 수 있게 합니다. 평균 풀링은 평균값을 계산해 대표값을 추출하기 때문에 노이즈를 감소시키고 입력 데이터의 다양한 변형에 강건한 모델을 구축하도록 도움을 줍니다.
### 일반적인 접근법의 제한 사항
그러나 풀링에도 문제점은 존재합니다. 풀링 영역이 너무 크면 입력 데이터의 세부 정보가 많이 손실될 수 있습니다. 이로 인해 모델은 입력 데이터의 중요한 특징을 놓치게 되며, 이는 과소적합(Underfitting)으로 이어질 수 있습니다. 모델이 학습 데이터에 맞지 않게 단순해지고, 새로운 데이터에 대한 일반화 능력이 저하됩니다. 반대로 풀링 영역이 너무 작으면 정보 중복이 발생할 수 있습니다. 작은 풀링 영역은 입력 데이터의 작은 변화를 무시하고 중요하지 않은 패턴을 강조할 수 있으며, 이는 Overfitting 문제로 이어질 수 있습니다. Average Pooling의 경우에도 평균을 계산하므로 입력의 세부 정보가 손실됩니다. 또한, 여전히 풀링 영역의 크기를 정수로 고정하는 한계가 존재하며, 풀링 영역이 겹치지 않도록 설정되어 일반화 능력이 저하될 수 있습니다.
### 제한 사항에 대한 해결 방안
Fractional Max-Pooling이라는 새로운 방법을 제시합니다. Fractional Max-Pooling은 전통적인 Max Pooling과 비슷한 개념을 가지고 있지만, 입력 특징 맵을 잘게 나누는 대신, 보다 정교한 위치 및 크기 조절을 허용하는 풀링 방법입니다. Fractional Max-Polling에서는 풀링 윈도우의 크기를 입력 데이터의 크기와 종횡비에 따라 결정합니다. 이것은 일반적으로 풀링 윈도우의 크기를 동적으로 선택할 수 있음을 의미합니다. 또한 위치 조절을 위한 파라미터나 알고리즘을 사용하여 풀링 윈도우의 위치를 입력 데이터 내에서 동적으로 결정합니다. 이는 입력 데이터의 위치를 보다 정확하게 조절하고 원하는 위치에 맞추는 데 사용됩니다. 유동적인 풀링 윈도우의 크기와 위치가 결정된 후, 각 풀링 윈도우 내에서 최대값, 가장 강한 특징을 추출합니다. 이는 Max-Pooling과 동일하게 동작하지만, 크기와 위치 조절을 허용하므로, 입력 데이터의 특정 부분을 더욱 정확하게 보존하고 추출할 수 있습니다. 이러한 특성은 CNN과 같은 딥러닝 모델에서 중요한 역할을 합니다.
# ComputerVision_김희원_교수님
## 프로젝트
### 문제 정의:
본 프로젝트의 주요 목표는 오디오 데이터를 이미지로 변환하는 방법을 개발하고 구현하는 것입니다. 오디오와 이미지 간의 변환은 다양한 응용 분야에서 유용하며, 예를 들어 음성 감지, 음악 시각화, 오디오 분류 및 검색, 보안 분야에서의 음성 인식, 음성 분석, 그리고 다른 시각적 정보 추출 작업에 사용될 수 있습니다. 오디오 데이터를 이미지로 변환하기 위해서는 오디오를 자연어로 변환시킨 후, 이를 바탕으로 이미지를 생성해야 합니다. 오디오 데이터를 자연어로 사용하기 위해 음악 캡셔닝(Music Captioning)이 되어있는 데이터 셋이 필요한데, 현재 음악 캡셔닝이 되어있는 대규모 공개 데이터셋은 너무나 부족하고 직접 만들기에는 많은 비용과 시간이 소요됩니다.

### 해당 문제에 대한 일반적인 접근법:
이러한 데이터 셋 부족 문제를 해결하기 위해 대규모 태그 데이터 셋에서 음악에 대한 설명 문장을 인위적으로 생성하기 위해 “LP-MusicCaps: LLM-BASED PSEUDO MUSIC CAPTIONING” 논문에서는 LLM을 사용할 것을 제안합니다. 먼저 기존 음악 태깅 데이터 세트에서 멀티 레이블 태그를 가져옵니다. 태그를 LLM의 입력하여 음악을 설명할 수 있는 문장으로 생성하여 반환하고, 캡션을 다는 작업 지침이 되는 프롬프트를 작성하여 문장을 분류하여 음악과 대응시킵니다. 음악 태깅 데이터에는 아티스트 이름이나 엘범 이름과 같은 정보가 있기 때문에 이를 바탕으로 생성된 문장을 분류하여 캡셔닝할 수 있습니다.

### 일반적인 접근법의 제한 사항 (from 논문 or 본인 생각)
하지만 promt to image 모델은 양식에 맞춰 입력해야만 프롬프트에 충실한 이미지를 얻을 수 있다. 음악 캡셔닝을 9가지의 양식을 학습시킨 LLM이 도출한 프롬프트와 음악 캡셔닝을 promt to image 모델에 직접 입력하고 비교하여 정확도를 확인했다. Batch count를 10으로 설정하고 프롬프트의 입력과 비슷하며 양질의 이미지의 개수를 비교했다. Sampling step을 80으로 두었을 때, 두 프롬프트 모두 양질의 이미지를 얻을 수 있었지만 9가지의 형식에 효과적인 키워드를 쓴 프롬프트는 모두 프롬프트에 충실하게 결과가 나왔으나, 음악 캡셔닝을 한 프롬프트가 일정 부분 무시되는 문제점을 보였다.

### 제한 사항에 대한 해결 방안 (from 논문 or 본인 생각)
Best Prompts for Text-to-Image Models and How to Find Them 논문에서 해결책을 알 수 있습니다. 사람들이 만족시킬 만한 이미지의 기준이 명확하게 정해진 것이 없기에 프롬프트 템플릿에 대한 대규모 인간 평가를 위한 접근 방식을 제안하여 이러한 격차를 해소하고자 합니다. 이 연구에서는 유전 알고리즘을 사용하여 가장 효과적인 프롬프트 키워드 조합을 발견하는 휴먼 인 더 루프(human-in-the-loop) 방법을 제안합니다. 작업자에게 설명과 한 쌍의 이미지가 제공되고, 작업자는 키워드 집합을 모른 채 가장 좋은 이미지를 선택해야 하는 **pairwise comparison crowdsourcing task**을 실행합니다. 각 설명에 대해, **Bradley-Terry 확률적 순위 알고리즘**을 사용하여 페어를 집계하여 인간에게 시각적으로 매력적으로 보이는 키워드 세트의 목록을 복구합니다. 

## 카메라 교정
### 문제 정의
자율주행차에서의 충돌 방지 및 환경 인식을 위해서는 레이다 장비를 사용하는 방법이 대부분입니다. 하지만 레이다 장비는 고가의 센싱 및 감지 장비 중 하나입니다. 따라서 비용을 절감하기 위해 전후방에 카메라를 설치하여 이미지에서 주변의 물체들 인식하는 과제가 나와 있습니다. 그러기 위해서는 주변의 물체들과 카메라 사이의 거리가 얼마인지 알 수 있어야 합니다. 우리가 실제 눈으로 보는 세상은 3차원이지만 이것을 카메라로 찍으면 2차원의 이미지로 투영변환하게 됩니다. 2차원 이미지 정보로 좌표계 변환을 통해 3차원의 공간 정보로 표현하는 동차좌표계를 사용할 수 있습니다. **실제 이미지는 사용된 렌즈, 초점 거리, 주점 등 카메라의 내부의 기구적인 부분에 의해서 크게 영향**을 받습니다.
### 해당 문제에 대한 일반적인 접근법
이러한 내부 요인의 파라미터 값을 구하는 과정을 **카메라 캘리브레이션(Camera Calibration)** 이라고 합니다. 3차원 점들이 영상에 투영된 위치를 구하거나 역으로 영상좌표로부터 3차원 공간좌표를 복원할 때에는 이러한 내부 요인을 제거해야만 정확한 계산이 가능해집니다. 초점 거리가 정확하지 않으면 거리 측정이 부정확해질 수 있으며, 이미지 중심이 정확하게 정의되지 않으면 영상 위치가 왜곡될 수 있습니다. 여기서 초점 거리는 픽셀 단위로 표현되며, 이미지 센서의 셀 크기의 상대적인 값으로 표현됩니다. 이러한 이유는  영상 좌표에서 3D 공간 좌표로의 변환을 기하학적으로 용이하게 하기 위함입니다.

### 일반적인 접근법의 제한 사항 (from 논문 or 본인 생각)
[출처](https://icserv.gist.ac.kr/mis/publications/data/2010/SKT%EA%B0%95%EC%9C%A4%EC%84%9D%EB%85%BC%EB%AC%B8.pdf)
하지만 여전히 교정 문제(Calibration Problems)와 **다시점 기하학 문제(Multi-view Geometry Problems)** 가 존재합니다. 다시점 기하학 문제는 여러 개의 카메라 시스템(다시점)을 사용하여 3D 공간의  물체를 여러 시점에서 관찰할 때 발생하는 기하학적 문제를 나타냅니다. 다시점 카메라 배열에서 발생하는 **기하학적 오차는 여러 대의 카메라가 일정하지 않은 위치와 방향으로 배열되는 것**으로부터 기인합니다. 이로 인해 상응점들의 수직 및 수평 변위 불일치가 발생할 수 있습니다. 같은 카메라 모델이라도 차이가 있는 내부 특성과 카메라 보정 (Camera calibration) 과정에서 생기는 오차도 기하학적 오차 발생의 원인이 됩니다. 이러한 기하학적 오차는 다시점 영상에서 각 시점간 상응점들의 수직 좌표와 수평 변위의 불일치로 나타나며 이것은 3차원 정보를 생성하고 활용함에 있어서 심각한 장애요소가 됩니다.

### 제한 사항에 대한 해결 방안 (from 논문 or 본인 생각)
**삼각 측량(Triangulartion)와 에피폴라 기하학(Epipolar Geometry)** 를 사용해서 다시점 기하학 문제를 해결할 수 있습니다. 삼각 측량은 서로 다른 시점에서 얻은 두 이미지로부터 3D 공간에서의 점 위치를 추정하는 방법입니다. 이를 위해 동일한 3D 점이 두 이미지에서 서로 다른 2D 좌표로 관찰됩니다. 즉, 서로 다른 시점의 이미지에서 관찰된 동일한 3D 점의 위치를 정확하게 계산하여 기하학적 오차를 줄일 수 있습니다. 또 다른 해결책으로는 에피폴라 기하학은 에피폴라 선 및 에피폴라 평면을 사용하여 상응점의 수직 및 수평 위치를 관찰하는 두 이미지 간의 상응 관계를 제한하고 정의하는 제약 조건을 제공합니다. 에피폴라 선을 평행 상태로 만들어 이를 통해 기하학적 오차를 줄이고, 서로 다른 시점의 이미지 간에 일관성을 유지할 수 있습니다. 두 기술은 서로 보완적으로 사용되어 다시점 영상에서 3D 정보를 정확하게 생성하고 활용할 수 있습니다.

## 입체 광도 계측
### 문제 정의
픽셀의 표면의 방향을 살펴보는 것은 컴퓨터 비전 및 3D 모델링 분야에서 중요한 문제입니다. **표면 법선 정보를 추정하는 것**은 더 현실적인 시각화, 물체 감지와 추격, 환경 모델링 그리고 물체 형태 복원과 같은 다양한 응용 분야에서 핵심적인 역할을 합니다. 따라서 표면 법선(normal) 정보를 정확하게 추정하는 것은 다양한 작업에 필수적입니다. 작업 중 대표적인 물체의 형태 복원을 위해서는 해당 지점에서의 표면 방향을 픽셀의 법선 벡터로 알 수 있기에 중요합니다. 광도 조절과 그림자 분석 같은 경우에는 표면의 방향에 따라 광도 조절이 달라지며, 그림자의 모양과 위치도 법선 벡터에 영향을 받습니다. 픽셀의 표면 방향을 파악하는 것을 제외하고 이러한 작업을 수행하는 것에는 한계가 있습니다.
### 해당 문제에 대한 일반적인 접근법
표면 법선은 **광도 방정식**을 활용하여 구할 수 있습니다. 표면에 대한 광도 모델을 선택합니다. 이 모델은 물체가 어떻게 빛을 반사하고 그림자를 만드는지 기술합니다. 광도 모델링에서 물체의 표면과 빛이 상호작용하는 방식을 모델링하는 수학적 표현 알베도를 구할 수 있습니다. 알베도 값은 광도 모델을 사용하여 물체의 그림자, 광도, 반사를 모델링할 때 중요한 역할을 합니다. 이후에 이미지의 픽셀에서 나오는 빛의 양, 광도 정보를 관측합니다. 광도 방정식은 광도 모델에서 표면 법선, 빛의 방향, 그림자 등의 정보를 통합하여 빛의 입사각, 반사각, 그리고 광도를 계산하는데 사용됩니다. 이러한 과정에서 표면의 곡률을 알 수 있습니다. 표면이 더 곡률이 높을 수록 반사된 빛은 더 큰 각도로 퍼저나가는 것을 이용하여 픽셀 간의 깊이 차이를 얻을 수 있습니다. 따라서, 광도 방정식을 푸는 과정에서 표면 법선과 픽셀의 깊이 정보를 추정할 수 있습니다. 
### 일반적인 접근법의 제한 사항 (from 논문 or 본인 생각)
실제 환경에서는 조명 조건이나 광도 정보가 불분명한 **Unknown lighting** 상태를 고려해야 합니다. 이 상태에서 단순 법선 벡터만을 사용하여 픽셀의 깊이 정보를 추정하는 것은 어렵습니다. Unknown lighting 상태에선 광도 방정식에 사용된 입력값이 정확하게 모델링 되지 않거나 알려져 있지 않기에, 빛의 방향과 강도를 정확하게 파악하기 어렵습니다. 
### 제한 사항에 대한 해결 방안 (from 논문 or 본인 생각)
Unknown lighting 상태를 해결하기 위한 방법은 **특이값 분해(Singular Value Decomposition, SVD)** 와 관련이 있습니다. SVD는 행렬을 세 개의 행렬로 분해하여 데이터를 더 잘 이해하고 표현할 수 있는 강력한 도구입니다. Unknown lighting 상태의 이미지를 사용하여 이미지의 픽셀 값(흑백 또는 컬러)을 생성한 후 SVD 분해를 적용합니다. 이후 평균 제거를 사용하여 이미지에서 난반사나 자연광과 같은 대상 물체에 빛이 동일하게 들어오는 조명 조건이 미치는 영향을 최소화하는 과정을 거칩니다. 이후에 SVD의 결과에서 가장 큰 특이값과 해당 특이값에 대응하는 특이벡터를 사용하여 조명 조건을 추정합니다. 이를 통해서 물체의 진짜 표면 특성을 추정하는데 도움을 줍니다.

## 특징 기술자
### 문제 정의
동일한 3D 장면을 다양한 시각에서 찍은 여러 이미지는 3D 구조에 대한 단서를 제공합니다. 이것이 "대응 문제" 라고 하며, 한 이미지에서 다른 이미지에서 동일한 지점으로 식별될 수 있는 지점 집합을 찾아야 합니다. 이것을 찾기 위해 하나의 이미지에서 다른 이미지와 대응하는 점을 찾아야 합니다. 카메라의 위치 정보를 알고 있거나 깊이 카메라를 사용하는 경우 각 지점 간의 관계를 파악하고 대응 점을 찾을 수 있습니다. 그러나 그런 경우가 아닌 경우, 관계를 알 수 없으므로 이미지의 특징을 추출하여 어떤 픽셀이 관련이 있는지를 결정해야 합니다. 이때 각 이미지에서 추출된 동일한 특징을 찾고 서로 대응시킵니다.
### 해당 문제에 대한 일반적인 접근법
이와 같은 특징을 찾고 일치시키기 위해 특징 기술자가 사용됩니다. 특징 기술자는 이미지에서 색상, 질감 또는 모양과 같은 고유한 정보를 캡처하도록 설계되며, 다른 이미지 영역과 분석 또는 비교할 수 있는 형식으로 이 정보를 표현합니다. 먼저 이미지의 주요 키포인트를 찾습니다. 주요 키포인트는 이미지 내 중요한 지점으로, 보통 객체의 고유한 특징을 나타내는 지점입니다. 예를 들어, 가장자리, 모서리, 반복적인 패턴 등이 있습니다. 그런 다음, 각 이미지에서 찾은 주요 키포인트의 유사성을 판단하고 이미지 간의 대응점을 찾습니다.
### 일반적인 접근법의 제한 사항 (from 논문 or 본인 생각)
그러나 특징 기술자는 환경 조건 및 변화에 대한 한계가 있습니다. 특징 기술자를 사용하여 특징을 추출하고 대응시키는 것은 이미지 주변 환경 조건의 변화에 영향을 받을 수 있습니다. 조명, 그림자 및 노이즈와 같은 환경 조건의 변화가 특징 추출의 정확성에 영향을 미칠 수 있습니다. 그리고 특징 기술자는 특정 변환에 대해 불변성을 가져야 할 필요가 있지만 모든 변환에 대해 불변성을 가져야 할 필요는 없으므로 변환 불변성의 균형을 찾기 어려울 수 있습니다. 또한 어떤 주요 키포인트를 선택하고 어떤 것을 무시할지에 대한 결정은 주관적일 수 있으며, 주관성은 결과의 일관성과 신뢰성에 영향을 미칠 수 있습니다.
### 제한 사항에 대한 해결 방안 (from 논문 or 본인 생각)
이러한 문제를 해결하기 위해 특징 추출 및 대응 알고리즘을 환경 조건 변화에 강건하도록 설계해야 합니다. 노이즈 제거 및 조명 보정 기술을 사용하여 이미지를 정규화하고, 다양한 환경 조건에서 특징을 추출할 수 있도록 합니다. 또한 다른 변환에 대한 불변성 추가합니다. 특정 변환에 대해 불변한 특징을 추출하려면 해당 변환에 대한 알고리즘을 사용합니다. 예를 들어, 회전 불변성이 필요한 경우, 회전 불변 특징 추출 알고리즘을 사용합니다. 그리고 주관성을 줄이기 위해 자동 키포인트 검출 알고리즘을 사용하고, 후에 필터링 프로세스를 통해 부적합한 키포인트를 제거합니다. 이러한 방법을 통해 환경 조건 변화, 변환 불변성 제한 및 키포인트 선택의 주관성과 관련된 제한 사항을 해결하고, 특징 추출 및 대응의 신뢰성과 유효성을 높일 수 있습니다.