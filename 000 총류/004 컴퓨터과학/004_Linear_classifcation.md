[출처](https://velog.io/@qsdcfd/Linear-classifiers#linear-classifier%EC%9D%98-%ED%95%9C%EA%B3%84)
## Concept
![[Pasted image 20231022181909.png]]
Parametric Approach를 함수 $f(x,W)$ 로 표현할 수 있어서, 이 함수의 출력 값은 분류하고 싶은 대상의 가짓수만큼 나오게 됩니다.
$$f(x,W)=W_{x}+ b$$
- b(bias)는 offset을 뜻하며 생략 가능합니다.
- $W_x$는 2차원 Parameter 행렬 $W$와 입력 이미지를 변환하여 만든 1차원 벡터 $x$사이의 행렬곱을 나타냅니다.
  
  1차원 벡터 $x$는 이미지의 spatial structure로 변환 과정에서 잃어버린 상태이다.
  Ex) 32 * 32 * 3 -> 3072 * 1
  ![[Pasted image 20231022182311.png]]

### Feature Transforms
![[Pasted image 20231022180934.png]]
선형으로 분류하기 어려운 부분들은 Feature Transforms를 사용하여 특성을 변형시키는 것으로 Geometric viewpoint나 visual point의 문제를 해결할 수 있으나 이미지는 고차원 유클리드 공간에서 존재합니다. 고차원 데이터에서는 더 많은 조건들을 고려해서 사용해야 합니다. 
#### Color Histogram
![[Pasted image 20231022180924.png]]
예를 들어 Color Histogram은 색상의 빈도를 통해 히스토그램 그래프를 만들어서 이미지를 분석합니다. Texture나 spacial positions를 무시하여 기존의 이미지 속 객체 각도 혹은 위치가 달라지는 문제를 해결할 수 있게 됩니다. 
#### Bag of Words
![[Pasted image 20231022180915.png]]
또 다른 예시로는 Bag of Words이 있습니다. 이는 학습 데이터의 각 이미지 별로 randomly하게 patch를 추출하고 각 patch들에 클러스터링을 한 후에 군집을 이루는 codebook(with visual word)를 만듭니다. 마지막으로 학습이 끝난 후에 이미지를 입력으로 받으면 어느 정도 visual word가 있는지 히스토그램을 통해 분석합니다.
  
## Problems
### Regularization, Initialization
선형 분류기는 이미지를 선형식으로 나타낸 후 분류하는 기법입니다. 이미지는 픽셀별 숫자의 형태, 즉 행렬의 형태로 나타나는데, 이 행렬의 특성을 이용하여 가중치 w와 편향값 b를 추가하여 선형식으로 변환하는 것입니다. 이미지의 행렬값을 하나의 열로 쭉 편 후, 가중치를 곱해주고 편향값을 더해주면 됩니다. 하지만 이러한 방법은 1차원 벡터에서는 유용하지만, ConvNet등과 같이 복잡한 경우 사용하기 어렵고 **가중치와 편향값이 서로 다른 방식으로 정규화되거나 초기화를 한 경우에는 적용이 어려워집니다**.

일반적인 접근법은 [가중치 정규화](004_Weight_Regularization)와 편향값 정규화(Bias Regularization)을 사용할 수 있습니다. 가중치 정규화에서는 주로 L1 정규화와 L2 정규화가 있습니다. 
### Parameter
좋은 결과를 얻기 위해서는 **적절한 가중치와 편향을 조정**하여 예측 값과 실제 값의 오차를 최소화하는 방향으로 사용해야 합니다. 선형 분류기는 일반적으로 손실 함수를 통하여 예측 값과 실제 값의 차이를 최소화하면서 자신의 파라미터를 검증합니다. 그러나 수작업으로 이러한 파라미터를 조정하는 것에는 한계가 있습니다.

이 과정에서 사용되는 것이 [경사 하강법](004_Gradient_Descent)입니다. 
### Hard Cases
허나 여전히 Linear Classifier는 1차원 벡터에서만 유용합니다. Linear Classifier은 한 개의 직선으로 두 개의 클래스를 제대로 분류할 수 없는 Hard Cases들이 존재합니다. 가장 대표적인 예시로 단층 퍼셉트론으로는 XOR 문제를 학습할 수 없습니다. 선형 결정 경계를 사용하여 비선형 문제들을 처리하는데 제한이 있으며, 선형 분류자만으로는 모든 종류의 이미지 분류 문제를 해결하기는 어렵습니다. 또한 실제 이미지 분류는 복잡한 도메인을 다룹니다. 예를 들어 객체 인식 문제에서 객체의 회전, 변형, 일부 뷰, 그림자 등을 처리해야 합니다. 선형 분류자는 이러한 다양한 상황을 고려하기 어려울 수 있습니다.

이러한 제한 사항에 대한 해결 방법은 이미지 분류 문제에서 선형 분류자의 제한을 극복하기 위해 비선형 모델을 사용하는 것입니다. 비선형 모델은 기존의 선형분류기가 해결하지 못한 비선형 관계를 모델링 할 수 있습니다. 대표적으로 비선형 SVM 분류라는 [서포트 벡터 머신](004_Support_Vector_Machine)이 있습니다.

또한 비선형성을 추가한 **신경망**(**Neural Network**)이 있습니다. 비선형 활성화 함수를 사용한 신경망은 복잡한 패턴을 학습할 수 있도록 입력 데이터를 변환합니다. 이 비선형성을 활용하여 다층 신경망(Multi-Layer Perceptron, MLP)을 구성합니다. MLP는 노드 수를 증가시켜 정확성을 높일 수 있지만 속도가 느려집니다. 따라서 층을 깊게 쌓음으로써 층별 노드 수를 줄일 수 있으며, 이로써 속도를 빠르게 만들 수 있습니다. 깊게 쌓인 은닉층은 입력층과 출력층 사이에 위치하며 중간 계산을 수행합니다. 각 은닉층은 입력 데이터를 받아 가중치와 활성화 함수를 사용하여 새로운 표현을 생성합니다. 이를 통해 다양한 수준의 추상적인 특징을 학습할 수 있습니다. 다층 구조를 사용함으로써 비선형성을 계층적으로 적용할 수 있습니다. 각 은닉층을 통과할 때마다 데이터는 더 복잡한 비선형 표현으로 변환되며, 이는 복잡한 패턴 및 특징을 학습하는 데 도움이 됩니다.