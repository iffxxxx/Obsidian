## Introduction
- ### What is probability?
	  확률 이론은 빈도주의적 해석과 베이지안 해석으로 나뉩니다. 빈도주의적 관점에서는 확률은 여러 번 반복된 사건의 장기적 빈도를 나타내며, 베이지안 관점에서는 확률은 불확실성이나 무지를 양적으로 표현하는 데 사용됩니다. 베이지안 해석은 일회성 사건에 대한 불확실성을 모델링할 수 있는 장점이 있습니다. 이 책에서는 베이지안 해석을 채택하며, 확률 이론의 기본 규칙은 채택된 해석과 무관하게 동일하게 적용됩니다.
- ### Types of uncertainty
	- **정의:**
		우리의 예측에서의 불확실성은 기본적으로 두 가지 다른 이유로 발생할 수 있습니다. 첫 번째는 데이터를 생성하는 기저의 숨겨진 원인 또는 메커니즘에 대한 무지 때문입니다. 이를 지식론적 불확실성이라고 하며, 더 간단하게는 모델 불확실성이라고도 합니다. 두 번째 종류의 불확실성은 더 많은 데이터를 수집해도 줄일 수 없는 고유한 변동성에서 발생합니다.
- ### Probability as an extension of logic
	- **정의:**
		  이 섹션에서는 확률의 기본 규칙을 Bool 논리의 확장으로 간주하는 것을 검토합니다.
		  
	- #### Probability of an event
		  우리는 이진 변수 A로 표시되는 사건을 세계의 어떤 상태로 정의합니다. 이 사건은 발생하거나 발생하지 않을 수 있습니다. 예를 들어, A는 "내일 비가 올 것이다" 또는 "어제 비가 내렸다" 또는 "라벨이 y = 1이다" 또는 "매개변수 θ가 1.5에서 2.0 사이에 있다"와 같은 사건이 될 수 있습니다. 표현 Pr(A)은 사건 A가 참일 확률(또는 A가 발생할 장기적인 비율)을 나타냅니다. 우리는 0 ≤ Pr(A) ≤ 1을 요구하며, 여기서 Pr(A) = 0은 사건이 확실히 발생하지 않을 것이고, Pr(A) = 1은 사건이 확실히 발생할 것이라는 것을 의미합니다.
		  
	- #### Probability of a conjunction of two events
		  두 사건이 동시에 발생할 확률을 우리는 다음과 같이 나타냅니다: 
		  $Pr(A ∧ B) = Pr(A, B)$
		  
		만약 A와 B가 독립적인 사건이라면, 다음의 관계가 성립합니다: 
		$Pr(A, B) = Pr(A) Pr(B)$
		
	- #### Probability of a union of two events
		  두 사건 A 또는 B가 발생할 확률은 다음과 같이 주어집니다: 
		  $Pr(A∪B)=Pr(A)+Pr(B)−Pr(A∩B)$
		
		만약 두 사건이 서로 배타적이라면 (즉, 동시에 일어날 수 없는 경우), 다음이 성립합니다: $Pr(A∪B)=Pr(A)+Pr(B)$
		
		예를 들어, X가 집합 $X=\{1,2,3,4\}$에서 균일하게 무작위로 선택된다고 가정해 봅시다. A를 X ∈ {1, 2}인 사건으로 정의하고, B를 X ∈ {3}인 사건으로 정의하면, 다음이 성립합니다: 
		$Pr(A∪B)=\frac{2}{4}​+\frac{1}{4}$
		
	- #### Conditional probability of one event given another
		  우리는 사건 A가 발생했을 때 사건 B가 발생할 조건부 확률을 다음과 같이 정의합니다: 
		  $Pr(B∣A)=Pr(A)Pr(A,B)​$
		
		만약 Pr(A) = 0이라면, 불가능한 사건에 대해 조건을 설정할 수 없으므로 이는 정의되지 않습니다.
		
	- #### Independence of events
		만약 사건 A와 B가 다음의 관계를 만족한다면, 우리는 사건 A가 사건 B와 독립적이라고 말합니다: $Pr(A,B)=Pr(A)⋅Pr(B)$
		
	- #### Conditional independence of events
		  만약 사건 A와 B가 사건 C가 주어졌을 때 다음의 관계를 만족한다면, 우리는 사건 A와 B가 사건 C에 대해 조건부로 독립적이라고 말합니다: 
		  $Pr(A,B∣C)=Pr(A∣C)⋅Pr(B∣C)$
		
		이것은 A ⊥ B|C로 표기됩니다. 사건들은 종종 서로 의존적일 수 있지만, 우리가 관련된 중간 변수에 대해 조건을 걸면 서로 독립적일 수 있습니다.
## Random variables
- **정의:**
	가정해 봅시다 X가 주사위를 굴렸을 때 나올 면의 방향과 같은 관심 있는 양을 나타내는 경우, 또는 현재 시간의 집 바깥의 온도와 같은 경우입니다. 만약 X의 값이 알려지지 않거나 변할 수 있다면, 우리는 이를 확률 변수(random variable 또는 rv)라고 부릅니다. 가능한 값들의 집합은 X로 표시되며, 이를 표본 공간(sample space) 또는 상태 공간(state space)이라고 합니다. 여러분은 주어진 표본 공간에서 발생하는 결과의 집합을 사건(event)이라고 합니다.
	
- ### Discrete random variables
	- **정의:**
		  만약 표본 공간 X가 유한하거나 셀 수 있는 무한이라면, X는 이산 확률 변수(discrete random variable)라고 불립니다. 이 경우, X가 값 x를 가질 확률을 나타내는 것은 Pr(X = x)로 표기됩니다. 확률 질량 함수(probability mass function 또는 pmf)는 확률 변수를 각 가능한 값에 설정하는 이벤트의 확률을 계산하는 함수로 정의됩니다: $p(x)=Pr(X=x)$
		  ![[Pasted image 20240105184435.png]]
		  그림에서는 X = {1, 2, 3, 4}에 정의된 두 개의 pmf를 보여줍니다. 왼쪽에는 균일 분포, p(x)=1/4, 오른쪽에는 퇴화 분포, p(x)=I(x=1) (여기서 $I()$는 이진 인디케이터 함수)가 있습니다. 그림 b의 분포는 X가 항상 값 1과 같다는 사실을 나타냅니다. (따라서 우리는 확률 변수가 항상 일정할 수도 있다는 것을 볼 수 있습니다.)
- ### Continuous random variables
	  만약 $X∈R$가 실수 값을 가지는 양이라면, 이를 연속 확률 변수(continuous random variable)라고 부릅니다. 이 경우, X가 취할 수 있는 유한한 또는 셀 수 있는 값들의 집합을 정의할 수 없습니다. 그러나 우리는 실수 축을 여러 구간으로 나눌 수 있습니다. 각 구간에 대해 X가 속하는 사건을 정의하면, 이산 확률 변수에 대한 방법과 유사한 방식으로 다룰 수 있습니다. 간단히 말해, X가 특정한 실수 값을 취할 확률을 해당 값이 속하는 구간의 크기를 제로로 수렴시켜 나타낼 수 있습니다.
	  
	- #### Cumulative distribution function (cdf)
		누적 분포 함수는 랜덤 변수가 특정 값보다 작거나 같을 확률을 나타내는 함수이다. '누적'이라는 이름은 특정 값보다 작은 값들의 확률을 모두 누적해서 구한다는 의미에서 붙여진 이름이다.
		
		예시를 통해 보겠습니다 . A = (X  <-a), B = (X <- b) and C = (a < X  b), where a < b. We have that
		
		B = A or C, and since A and C are mutually exclusive
		이러한 사건이 있을때, A와 C가 mutually exclustive 하다면 위에서 배웠던 것 처럼, 
		
		Pr(B) = Pr(A) + Pr(C) 로 표시할 수 있습니다.
		이떄, 구간 C에 있을 확률을 구해보면 Pr(C) = Pr(B) - Pr(A) 로 표시할 수 있게 됩니다.
		
		이제 cdf 를 정의해보면, random variable X에 대해서
		
		P(x) =^ Pr(X=x)  → Capital P는 cdf로 정의합니다.
		
		 C를 다시 살펴보면 ,구간 a<X<b에 있을 확률 Pr(a<X<=B) = P(b) - P(a) 로 구할 수 있습니다.
	
	- #### Probability density function (pdf)
		확률 밀도 함수
		정의는 small p(x) 는 cdf를 미분한 값으로 정의합니다.
		이때, 미분값이 항상 존재하는것은 아니기 때문에, pdf가 정의되지 않는 경우도 존재하게 됩니다.
		만약, 연속 확률 변수 (crv)가 유한 구간에서 존재한다고 했을때,  
		cdf를 적분하는것으로 pdf를 계산 할 수 있고, 
		구간의 간격이 매우 작아질떄, 다음과 같이 정의될 수 있습니다.
- ### Sets of related random variables
	- **정의:**
		  이 섹션에서는 관련된 두 확률 변수 집합에 대한 분포에 대해 논의합니다.
		
		먼저 두 확률 변수 X와 Y가 있을 때, 두 확률 변수의 결합 분포를 정의할 수 있습니다. 모든 가능한 X와 Y의 값에 대해 p(x, y) = p(X = x, Y = y)로 정의합니다. 두 변수가 유한한 집합일 경우, 결합 분포를 2차원 표로 나타낼 수 있으며, 표의 모든 항목은 1의 합을 갖습니다. 예를 들어, 두 이진 변수의 다음 예를 살펴보겠습니다:
		![[Pasted image 20240105190853.png]]
		
		만약 두 변수가 독립적이라면, 결합 분포를 두 주변 분포의 곱으로 나타낼 수 있습니다. 두 변수가 유한한 카디널리티를 갖는 경우, 2차원 결합 표를 두 1차원 벡터의 곱으로 나타낼 수 있습니다.
		
		주어진 결합 분포가 있을 때, 확률 변수의 주변 분포는 다음과 같이 정의됩니다:
		
		$p(X=x)=∑y​p(X=x,Y=y)$
		
		여기서 우리는 Y의 모든 가능한 상태에 대해 합산합니다. 이는 때로 합의 규칙 또는 총 확률의 규칙이라고 불리기도 합니다. p(Y = y)는 비슷한 방식으로 정의됩니다. 예를 들어, 위의 2차원 표에서 p(X = 0) = 0.2 + 0.3 = 0.5이고, p(Y = 0) = 0.2 + 0.3 = 0.5입니다. ("주변"이라는 용어는 표의 행과 열의 합계를 표의 테두리 또는 여백에 쓰는 회계 관행에서 비롯됩니다.)
		
		우리는 확률 변수의 조건부 분포를 다음과 같이 정의합니다:
		
		$p(Y=y∣X=x)=p(X=x)p(X=x,Y=y)​$
		
		이 식을 재배열하여 $p(x,y)=p(x)p(y∣x)$를 얻을 수 있습니다.
- ### Independence and conditional independence
	  우리는 X와 Y가 무조건적으로 독립적이거나 주변적으로 독립적이라고 말하며, 기호로는 $X⊥Y$로 나타냅니다. 만약 우리가 결합 분포를 두 주변 분포의 곱으로 나타낼 수 있다면
	
	$X⊥Y⇔p(X,Y)=p(X)p(Y)$
	
	일반적으로, 변수 집합 $X1​,…,Xn$​이 (상호적으로) 독립적이라고 말하면, 결합 분포를 모든 부분 집합 $X_1​,…,X_m​⊆X_1​,…,X_n$​에 대해 다음과 같이 쓸 수 있다:
	
	$p(X_1​,…,X_m​)=∏_{i=1}{m}​p(X_i​)$ (2.22)
	
	예를 들어, $X_1​,X_2​,X_3$​이 상호적으로 독립이라면 다음 조건이 성립합니다: 
	
	불행히도, 무조건적 독립성은 드물며, 대부분의 변수는 대부분의 다른 변수에 영향을 미칠 수 있습니다. 그러나 일반적으로 이 영향은 직접적인 것이 아닌 다른 변수를 통해 중재됩니다. 따라서 우리는 X와 Y가 주어진 Z 하에서 조건부로 독립적이라고 말합니다. 만약 조건부 결합이 조건부 주변 분포의 곱으로 나타낼 수 있다면:
	
	$X⊥Y∣Z⇔p(X,Y∣Z)=p(X∣Z)p(Y∣Z)$
	
	이 가정은 X − Z − Y 그래프로 나타낼 수 있으며, 이는 X와 Y 간의 모든 의존성이 Z를 통해 중재된다는 직관을 캡처합니다. 더 큰 그래프를 사용하여 복잡한 결합 분포를 정의할 수 있습니다.
- ### Moments of a distribution
	- **개요:**
		  이 섹션에서는 확률 분포(확률 밀도 함수 또는 확률 질량 함수)에서 파생될 수 있는 다양한 요약 통계량에 대해 설명합니다.
- ### Limitations of summary statistics
	- **문제정의:**
		    요약 통계량(평균 및 분산과 같은)을 사용하여 확률 분포(또는 분포에서 샘플링된 점들)를 요약하는 것은 일반적이지만, 이로 인해 많은 정보가 손실될 수 있습니다. 이를 보여주는 두 예시가 있습니다.
		
		1. **Anscombe's Quartet**: Anscombe은 평균, 분산 및 상관 계수와 같은 특징이 완전히 동일한 4개의 데이터셋을 만들어냈습니다. 이것들은 그래프로 표현되었을 때 매우 다른 모양을 가지고 있습니다. 이는 통계학자들 사이에서 수치적 요약이 데이터 시각화보다 우월하다는 인상을 뒤엎기 위한 것이었습니다.
		    ![[Pasted image 20240105191546.png]]
		    동일한 낮은 차수의 요약 통계량을 가지고 있는 12개의 데이터셋으로 구성되어 있습니다. 낮은 차수의 통계량은 평균, 분산과 같은 간단한 통계량을 말합니다. 이러한 12개의 데이터셋 중 하나는 공룡 모양을 가지고 있지만, 다른 11개는 완전히 다른 모양을 가지고 있습니다. 이것은 동일한 통계적 특성을 가진 데이터가 여러 형태로 나타날 수 있으며, 수치적 요약만으로는 이러한 차이를 파악하기 어렵다는 사실을 강조합니다.
		    
		2. **Datasaurus Dozen**: 이 예시는 고작렬 통계량을 가진 12개의 데이터셋으로 구성되어 있습니다. 이 중 하나는 공룡 모양을 가지고 있습니다. 그러나 나머지 11개의 데이터셋은 완전히 다른 모양을 가지고 있습니다. 이러한 데이터셋은 Datasaurus Dozen이라고 불리며, 이것은 순수한 통계량만으로는 차이를 알아볼 수 없다는 사실을 보여줍니다.
		
		이러한 예시들은 통계량만으로는 데이터의 다양성을 충분히 반영할 수 없다는 한계를 보여줍니다. 따라서 데이터를 시각화하여 더 깊게 이해하는 것이 중요합니다.
## Bayes' rule
- **정의:**
	베이즈 정리 또는 베이즈 규칙은 확률 이론과 베이지안 추론의 핵심 개념 중 하나입니다. Harold Jeffreys 군은 이것의 중요성을 기하학에서의 피타고라스의 정리와 비교했습니다.
	
	베이즈 정리는 관측된 데이터 (Y = y)가 주어졌을 때 알려지지 않은 어떤 양 (보통 H로 표시)에 대한 확률 또는 확률 분포를 계산하는 공식입니다. 베이즈 정리의 수식은 다음과 같습니다:
	
	$p(H=h∣Y=y)=p(Y=y)p(H=h)⋅p(Y=y∣H=h)​$ 
	
	여기에서:
	
	- $p(H=h∣Y=y)$는 관측된 데이터 $Y = y$가 주어졌을 때 알려지지 않은 양 $H$에 대한 가능한 값들에 대한 확률 분포를 나타냅니다.
	- $p(H=h)$는 $H$에 대한 사전 확률로, 새로운 데이터를 고려하기 전의 초기 신념을 나타냅니다.
	- $p(Y=y∣H=h)$는 가설 H의 값이 주어졌을 때 데이터 Y = y를 관측할 확률로, 주어진 가설이 관측된 데이터를 얼마나 잘 설명하는지를 나타냅니다.
	- $p(Y=y)$는 관측된 데이터의 주변 확률로, 정규화 요소로 작용합니다.
	
	베이즈 정리는 새로운 증거를 고려하여 가설에 대한 신념을 업데이트하는 데 사용되며, 이를 통해 사전 신념과 관측 데이터를 기반으로 사후 확률을 계산할 수 있습니다.
- ### Inverse problems
	- **정의:**
		확률 이론은 세계의 상태 h에 대한 지식(또는 가정)을 기반으로 결과 y에 대한 분포를 예측하는 데 관여합니다. 반면에, 역확률은 결과의 관측으로부터 세계의 상태를 추론하는 데 관심이 있습니다. 이를 h → y 매핑을 뒤집는 것으로 생각할 수 있습니다.
		
	- **구현:**
		  이러한 역문제에 대처하기 위해 우리는 베이즈 규칙을 사용하여 사후 분포 p(h|y)를 계산할 수 있습니다. 이는 가능한 세계의 상태에 대한 분포를 제공합니다. 이를 위해서는 순방향 모델 p(y|h)과 사전 p(h)을 지정해야 합니다. 순방향 모델은 (또는 불가능한 세계 상태를 제외하거나 가중치를 줄이는 데 사용될 수 있는) 신뢰성 없는 세계 상태를 판별하기 위해 필요합니다.
## Bernoulli and binomial distributions
- ### Definition
	- **정의:**
		  동전을 던질 때, 동전이 앞면이 나올 확률을 0 ≤ θ ≤ 1로 나타냅니다. 여기서 Y = 1은 앞면이 나온 사건을 나타내고, Y = 0은 동전이 뒷면에 떨어진 사건을 나타냅니다. 따라서 p(Y = 1) = θ 및 p(Y = 0) = 1 − θ로 가정합니다. 이를 베르누이 분포라고 하며
		  
	- **표기:**
		  $Y∼Ber(θ)$
		  여기서 θ는 앞면이 나올 확률을 나타냅니다. 이러한 분포는 동전 던지기와 같은 이진 사건을 모델링하는 데 사용됩니다.
- ### Sigmoid (logistic) function
	- **정의:**
		binary value y = {0,1}을 주어진 인풋 x에서 에측하길 원한다고 가정해보면, 우리는 조건부 확률 분포를 사용 할수 있습니다.
		
		이는 식2.71과 같이 표시할 수 있는데,  여기서 f(x, 세타) 는 출력분포의 평균 매개변수를 에측하는 함수입니다.  여기서 f의 필요충분조건인 $[0,1]$을 피하기 위해, 
		
		sigma를 정의하여 사용하게 됩니다. 이때 이 시그마를 sigmoid function 또는 logistic function이라고 부르게 됩니다.
		
		**a를 “sigmoid term”이라고 부릅니다.**
- ### Binary logistic regression
## Categorical and multinomial distributions
- ### Definition
	범주 분포(Categorical distribution)는 각 클래스마다 하나의 매개변수를 가지는 이산 확률 분포입니다. 수식으로 나타내면 다음과 같습니다:
	
	$Cat(y∣θ)=∏c=1C​θcI(y=c)​$
	
	여기에서 $I(y=c)$는 y가 c일 때 1이고 그렇지 않을 때 0인 지시 함수(indicator function)를 나타냅니다. 다시 말해, $p(y=c∣θ)=θ_c​$입니다. 매개변수는 $0 ≤ θ_c ≤ 1$ 및 $∑_{c=1}^{C}​θ_c​=1$로 제한되어 있어_ C-1개의 독립적인 매개변수만 존재합니다.
	
	범주 분포를 또 다른 방법으로 표현할 수 있는데, 이는 이산 변수 y를 해당 클래스 레이블에 해당하는 항목을 제외하고 모두 0인 C개의 원-핫 벡터(one-hot vector)로 변환하는 것입니다. 여기서 "원-핫"이란 이진 벡터를 전기 공학에서 사용되는 것과 연결된 용어로, 이진 벡터가 일련의 전선에 전기적인 활성화 또는 비활성화를 나타내기 때문입니다. 예를 들어, C = 3인 경우 클래스 1, 2 및 3은 각각 (1, 0, 0), (0, 1, 0), (0, 0, 1)로 인코딩됩니다. 보다 일반적으로 클래스는 차원 c에서만 1이고 나머지는 모두 0인 단위 벡터(unit vector)로 인코딩할 수 있습니다. 이를 원-핫 인코딩이라고 하며, 이를 사용하여 범주 분포를 다음과 같이 표현할 수 있습니다:
	
	$Cat(y∣θ)=∏_{c=1}^{C}​θ_c^{y_c}​$​ (2.89)
- ### Softmax function
	위에서 본 것처럼, 카테고리 분포를 따르는 식을 정의해보면, 다음 식과 같이 되고,
	
	여기서 fc(x;세타)는 0과 1사이의 값이고, f_c(x;세타)의 시그마는 1입니다.  시그마는 모든 클래스에 대해서 1 값을 결과로 도출합니다.
	
	이때, 함수 f가 확률 벡터를 직접 예측하도록 설정되어 있는것을 피하기 위해 f를 소프트 맥스 함수로 정의합니다. 
	
	소프트 맥스 함수는 식 2.94와 같이  정의됩니다. 이 함수는 $[0,1]$사이의 값으로 매핑되며, 소프트맥스의 범위는 0과 1사이입니다. 그리고 시그마 소프트맥스는 1을 만족하는 함수입니다. 이는 소프트맥수함수의 모든 출력의 확률이 1이라는 것을 의미합니다.

## Univariate Gaussian (normal) distribution
- ### Cumulative distribution function
	  Cumulative Distribution Function (CDF)는 연속 확률 변수에 대해 다음과 같이 정의됩니다:
	
	$P(y) , Pr(Y ≤ y)$
	
	여기서 P는 CDF를 나타냅니다. CDF는 어떤 구간에 대한 확률을 계산할 수 있습니다. 또한, CDF는 단조 증가 함수입니다. 단조 증가한다는 것은 변수의 값이 증가함에 따라 누적 확률이 감소하지 않는다는 것을 의미합니다. 이는 다음과 같이 정의됩니다:
	
	$Pr(a < Y ≤ b) = P(b) − P(a)$
	
	가우시안 분포에서의 CDF는 다음과 같이 정의됩니다:
	
	![[Pasted image 20240105193821.png]]
	
	여기서 $N(z∣μ,σ^2)$은 가우시안의 확률 밀도 함수를 나타냅니다. 이 함수는 평균 μ에서 최대값을 가지며, 분산 $σ^2$에 따라 곡선의 폭이 결정됩니다.
	
	정규분포에서의 CDF는 확률 변수 Y가 특정 값 y 이하일 확률을 나타냅니다. 매개변수 μ는 평균을 나타내며, 최빈값과 동일합니다. $σ^2$는 분산을 나타냅니다. μ=0이고 σ=1인 경우를 표준 정규 분포라고 합니다.
	
- ### Probability density function
	  확률밀도함수(PDF)는 누적분포함수(CDF)의 도함수로 정의되며, 가우시안의 경우 다음과 같이 주어집니다:
	
	$N(y∣μ,σ^2)=2πσ2​1​exp(−2σ21​(y−μ)2)$
	
	PDF를 통해 연속 변수가 특정 간격에 속할 확률을 계산할 수 있으며, 간격의 크기가 작아질수록 다음과 같이 근사할 수 있습니다:
	
	$Pr(y≤Y≤y+dy)≈p(y)dy$
	
	PDF를 사용하여 분포의 평균과 분산을 계산할 수 있습니다. 평균은 다음과 같이 정의되며, 가우시안의 경우 평균은 그대로입니다:
	
	$E[Y]=∫_{−∞}^{∞}​y_p(y)dy$
	
	분산은 퍼짐의 측정값으로 정의되며, 가우시안의 경우 다음과 같은 관계를 가집니다:
	
	$E[Y_2]=σ_2+μ_2$
	
	표준 편차는 분산의 양의 제곱근으로 정의됩니다:
	
	s$std[Y]=V[Y]​=σ$

- ### Why is the Gaussian distribution so widely used? 
	왜 가우시안 분포가 널리 사용되는가 ? 
	
	첫쨰 가우시안분포는 해석하기 쉬운 두개의 매개변수를 가지고 있고, 분포의 가장 기본적인 특성인 평균과 분산을 알 수 있습니다.
	
	둘째 중심극한정리(2.8.6)에 따르면 독립적인 확률변수들의 합은 대략 가우시안 분포를 따른다고 말해줍니다. 이는 오류나 노이즈를 모델링하는데 매우 좋은 선택입니다.
	
	셋째, 가우시안 지정된 평균과 분산을 가지는 제약조건 하에 최대한 적은 가정을 한다는 점에서, 섹션 3.4.4.에서 보여주듯이 많은경우에 좋은 기본선택이 됩니다.
	
	마지막으로 수학적으로 형태가 간단하기때문에 자주 사용합니다.

## Transformations of random variables
- ### Discrete case
	  만약 X가 이산형 확률 변수(discrete rv)이면, Y에 대한 확률질량함수(pmf)는 f(x)가 y인 모든 x에 대한 확률 질량을 더하여 다음과 같이 얻을 수 있습니다:
	
	$pY​(y)=∑_{x:f(x)=y}​p_X​(x)$ 
	
	예를 들어, 만약 $f(X)$가 X가 짝수이면 1, 그렇지 않으면 0을 반환하고, $pX​(X)$가 {1, 2, ..., 10}에서 균일하게 분포한다면, $Y​(1)=P_X∈{2,4,6,8,10}​p_X​(x)=0.5$이 되고, 따라서 $pY​(0)=0.5$가 됩니다. 이 예제에서 f는 다 대 일 함수입니다.
- ### Continuous case
	만약 X가 연속형 확률 변수이면, 위의 식을 사용할 수 없습니다. 왜냐하면 pX​(x)는 확률 질량이 아니라 밀도이며, 밀도를 더할 수 없기 때문입니다. 대신에 다음과 같이 cdf를 사용합니다:
	
	$P_Y​(y)=Pr(Y≤y)=Pr(f(X)≤y)=Pr(X∈{x∣f(x)≤y})$
	
	만약 f가 역함수(invertible)인 경우, cdf를 미분하여 y에 대한 pdf를 도출할 수 있습니다. 그렇지 않은 경우, 수치적 적분 또는 몬테카를로 근사화를 사용할 수 있습니다.
- ### The convolution theorem
	확률 이론에서 합의 분포를 결정하기 위해 종종 합성 공식을 사용합니다. 이것은 두 확률 변수의 합의 분포를 결정하는 데에 적용되는데요. 이를 설명해보겠습니다:
	
	1. **이산 케이스:**
	    
	    - 만약 x1​과 x2​가 독립적인 이산 확률 변수라면, 그들의 합 $y=x1​+x2$​의 확률 질량 함수(pmf)는 합성 공식에 의해 아래와 같이 주어집니다: 
		    $p(y=j)=∑k​p(x1​=k)⋅p(x2​=j−k)$
	    - 이 공식은 x1​과 x2​의 값 중 특정한 합 j를 얻을 확률을 구하는데 사용됩니다.
	2. **연속 케이스:**
	    
	    - 확률 변수 x1​과 x2​가 확률 밀도 함수(pdf)를 갖는 경우, 그들의 합 y=x1​+x2​의 분포는 합성 공식을 사용하여 결정됩니다.
	    - 누적 분포 함수(cdf)는 다음과 같이 주어집니다: 
		    $P_Y​(y^∗)=∫_{−∞}{∞}​p_1​(x_1​)(∫_{−∞}^{y^∗−x_1}​​p_2​(x_2​)dx_2​)dx_1​$
	    - 확률 밀도 함수(pdf)는 cdf를 $y^∗$에 대해 미분함으로써 얻어집니다: 
		    $p(y)=dy∗d​P_Y​(y^∗)$
	    - 결과는 p1​과 p2​의 합성으로 표현되며, 이는 p=p1​∗p2​로 나타냅니다.
	3. **합성 연산:**
	    
	    - 합성은 "뒤집고 끌어오기" 작업으로 생각할 수 있습니다. 한 함수를 뒤집어 다른 함수 위로 슬라이드하고 각 겹치는 지점에서 곱을 누적합니다.
	    - 벡터의 길이가 유한한 경우, 합성은 벡터를 뒤집은 다음 요소별 곱을 합산하는 것으로 생각할 수 있습니다.
	
	요약하면, 합성 공식은 독립적인 두 확률 변수의 합의 분포를 결정하는 데 사용되는 방법을 제공합니다.
- ### Central limit theorem
	- **정의:**
		  중심 극한 정리(Central Limit Theorem, CLT)는 독립적이고 동일하게 분포된(random and identically distributed) N개의 확률 변수의 합이 N이 커짐에 따라 정규 분포에 수렴한다는 원리를 제시합니다. 이 정리는 다양한 분포에 대해 적용될 수 있지만, 각 확률 변수가 동일한 평균(µ)과 분산(σ^2)을 갖는 경우에 대한 설명을 살펴보겠습니다.
	
	- **예시:**
		N개의 독립적이고 동일하게 분포된 확률 변수 $X_1​,X_2​,...,X_N​$이 있고, 이들의 합을 $S_N​=X_1​+X_2​+...+X_N$​이라고 합시다. 이때, 중심 극한 정리에 따르면 N이 충분히 크다면 ��SN​의 분포는 근사적으로 정규 분포에 수렴합니다.
	
		중심 극한 정리에 따르면 $S_N$​의 확률 밀도 함수(pdf)는 다음과 같이 근사됩니다: 
		$p(S_N​=u)=\frac{1}{\sqrt{2πNσ^{2}​}}exp\bigg(\frac{(u−Nμ)^2​}{−2Nσ^2}\bigg)$
		여기서,
		
		- $S_N$​은 N개의 독립적인 확률 변수의 합입니다.
		- μ는 각 확률 변수의 평균입니다.
		- $σ^2$은 각 확률 변수의 분산입니다.
		- u는 $S_N$​의 특정 값입니다.
		
		즉, $S_N$​의 분포는 N이 증가함에 따라 정규 분포의 형태를 띄게 되며, 정규 분포의 평균은 $N_μ$, 분산은 $Nσ^2$이 됩니다. 이는 많은 독립적인 무작위 변수들의 합이 정규 분포를 따른다는 중요한 결과로서, 통계학과 확률 이론에서 널리 사용됩니다.
- ### Monte Carlo approximation
	- **정의:**
		  Monte Carlo 근사화(Monte Carlo Approximation)는 어떤 확률 변수 �x와 그에 따른 함수 y=f(x)의 확률 분포 �(�)p(y)를 해석적으로 계산하기 어려운 경우, �x의 분포로부터 많은 표본을 추출하고 이를 이용하여 �(�)p(y)를 근사화하는 간단하면서도 강력한 방법입니다.
## Exercises
