## Introduction
확률 모델의 모든 매개변수 θ가 알려져 있다고 가정했습니다. 
이번 장에서는 데이터에서 이러한 매개변수를 학습하는 방법에 대해 설명합니다.
**D로부터 θ를 추정하는 과정을 모델 피팅 또는 트레이닝이라고 하며, 머신 러닝의 핵심**입니다.
이러한 추정치를 생성하는 방법에는 여러 가지가 있지만, 대부분은 다음과 같은 형태의 최적화 문제로 귀결됩니다.
$$\hat{\theta}=argmin\;L(\theta)$$
여기서 L(θ)는 일종의 손실 함수 또는 목적 함수입니다. 
이 장에서는 몇 가지 다른 손실함수에 대해 설명합니다.
## Maximum likelihood estimation(MLE)
- ### Definition
1. **정의:**
	
    - MLE은 데이터셋 D에 대한 likelihood 함수 $p(D|\theta)$를 최대화하는 매개변수 $\theta$를 찾는 것으로 정의됩니다.
    - $\theta_{mle}=arg⁡max⁡_{\theta}\;p(D|\theta)$
	     
	     데이터가 임의의 파라미터 $\theta$에 의존하는 확률분포를 따르고 있는 표본 데이터가 주어졌을 때,
	     $v_1,v_2,\cdots,v_n$
	     
	     데이터가 발생할 확률을 구하고 싶다.
	     $p(v_1,\cdots,v_n|\theta)$
		 
		 하지만 현재 $\theta$를 모르기에 베이즈 규칙을 이용하여 $\theta$가 발생할 우도 (주어진 표본들에 비추어봤을 때 모집단의 모수 $\theta$에 대한 추정값)으로 바꾸어 생각할 수 있다.
		 $L(\theta|v_1,\cdots,v_n)$
2. **딥러닝에서의 추론:**
    
    - 딥러닝에서 "추론"은 "예측"으로 참조되며, 특정한 입력 x에 대한 출력 y의 확률 $p(y∣x,\hat{\theta})$를 계산하는 것을 의미합니다.
3. **독립 동일 분포 가정:**
    
    - likelihood 함수는 각 예제의 독립성과 동일한 분포를 가정한 것으로 표현됩니다.
    
4. **로그 우도:**
    
    - 로그 우도 $L(\theta)$는 각 예제에 대한 로그 확률의 합으로 표현됩니다.
    - $L(\theta)=\sum_{n=1}^{N}\;log\;p(y_{n}|x_{n},\theta)$
    
    - 로그 우도 함수를 사용하는 이유
		- 우도 함수는 0에서 1사이에 값을 취함
			  우도 함수에 로그값을 취해 $-\infty<ln\;L<=0$
	    - 우도 함수의 값은 사례수가 많은 경우에는 극히 작은 값
5. **MLE 목적 함수:**
    
    - MLE는 로그 우도를 최대화하는 것으로 정의되며, 최적화 문제로 표현됩니다:
	      최적화 알고리즘을 사용하여 이 목적 함수를 최대화하면, 모델의 파라미터를 찾을 수 있다.
        - $\hat{\theta}_{mle}=arg⁡max⁡_{\theta}\;L(\theta)$
6. **음의 로그 우도 (NLL : Negative Log Likelihood):**
    
    - 목적에 따라 최적화를 위해 (비용 함수를 최소화하기 위해) 음의 로그 우도가 일반적으로 사용됩니다.
    - $NLL(\theta)=-\sum_{n=1}^{N}\;log\;p(y_{n}|x_{n},\theta)$
7. **무조건적 (비지도) MLE:**
    
    - 무조건적 (비지도) 모델의 경우, 출력 $y_{n}$은 있지만 입력 $x_{n}$이 없을 때 음의 로그 우도를 최소화하여 MLE를 찾습니다.
    - $\hat{\theta}_{mle}=arg⁡min⁡_{\theta}\;-\sum_{n=1}^{N}\;log\;p(y_{n}|\theta)$
8. **입출력의 결합 우도:**
    
    - 어떤 경우에는 <font color="#d99694">입력과 출력의 결합 우도를 최대화</font>하고 싶을 수 있습니다.
	      입력과 출력 간의 상관 관계를 모델로써 잘 파악하고자 하는 목적을 나타내는 표현
    - $\hat{\theta}_{mle}=arg⁡min⁡_{\theta}\;-\sum_{n=1}^{N}\;log\;p(y_{n}|\theta)$

요약하면, MLE는 통계 모델의 매개변수를 likelihood 함수를 최대화하여 추정하는 방법으로, 딥러닝에서는 입력을 주고 출력을 예측하는 작업에 사용됩니다. 음의 로그 우도는 일반적으로 최적화의 목적 함수로 사용되며, 조건부와 결합 우도는 모델링 작업에 따라 선택됩니다.

- ### Justification for MLE
1. **Bayesian 해석:**
    
    - MLE를 베이지안 관점에서 바라볼 수 있습니다. 
	      베이지안 관점에서 MLE는 베이지안 사후 확률인 $p(\theta|D)$를 균일한 사전 분포(uniform prior)를 사용한 델타 함수(delta function)로 근사화한 것으로 볼 수 있습니다.
	      
	     베이지안 통계에서 사후 확률은 **베이즈 정리**를 사용하여 다음과 같이 표현됩니다:
	     
	     $p(\theta|D)=\frac{p(D|\theta)\cdot p(\theta)}{p(D)}$
	     여기서 $p(D∣θ)$는 likelihood, $p(θ)$는 prior, $p(D)$는 evidence(데이터의 확률)입니다. 베이지안 추론에서는 posterior($\theta$에 대한 확률분포)를 구하기 위해 prior와 likelihood의 곱을 evidence로 나누어야 합니다.
	     만약 균일한 사전 분포를 사용한다면, prior $p(θ)$는 상수가 되어 posterior를 likelihood로만 구하는 것과 같아집니다.
	     
    - $\theta_{map}=argmax_{\theta}\;log\;p(\theta|D)=argmax_{\theta}\;log\;p(D|\theta)+log\;p(\theta)$
	     $log\,p(θ)$는 상수이기 때문에 최적화에 영향을 미치지 않습니다. 따라서 균일한 사전 분포를 사용하면, MLE를 구하는 것과 동일한 결과를 얻게 됩니다.
	      $\theta_{map}=\theta_{mle}$
2. **예측 분포의 근사:**
    
    - 또 다른 MLE를 정당화하는 방법은 얻어진 예측 분포 $p(y|\theta_{mle}​)$가 데이터의 경험적 분포(empirical distribution)와 가능한 비슷하도록 만드는 것입니다.
	      
	     예측 분포는 모델이 주어진 파라미터 MLEθMLE​를 기반으로 얻은 결과물인데, 이 분포가 실제 데이터의 경험적 분포와 유사하면 모델이 데이터를 잘 설명하고 있다고 할 수 있습니다.
	    
    - KL(Kullback-Leibler) 다이버전스를 사용하여 두 분포 간의 유사성을 측정합니다.
	      
	    KL 다이버전스를 최소화하는 것은 MLE를 수행하는 것과 동일하며, 이는 Negative Log Likelihood(NLL)를 최소화하는 것과도 동일합니다.
	    
    이를 통해 모델이 주어진 데이터의 경험적 분포와 가능한 가까워지도록 모델을 학습하는 것이 MLE를 정당화하는 한 가지 방법임을 보여줍니다.

MLE는 베이지안 관점에서는 균일한 사전 분포를 사용한 베이지안 추론의 특별한 경우로 해석되며, 예측 분포의 경험적 분포와의 유사성을 최대화함으로써 정당화될 수 있습니다.

- ### Example
	- #### Bernoulli 분포에 대한 MLE
		
		- **베르누이 분포:** 동전 던지기의 결과를 나타내는 확률변수 $Y$를 고려하고, 이때 이벤트 $Y=1$은 앞면을 나타내고 $Y=0$은 뒷면을 나타냅니다. 확률 $\theta$는 앞면이 나올 확률입니다.
		- **Negative Log Likelihood (NLL):** 베르누이 분포의 NLL은 다음과 같이 정의됩니다. 
			
			$NLL(\theta)=−\sum_{n=1}^{N}​[I(y_{n}​=1)log\;\theta+I(y_{n}​=0)log(1-\theta)$] 여기서 $I$는 지시함수입니다.
		- **MLE 계산:** NLL를 최소화하기 위해 편미분하여 미분이 0이 되는 값을 찾습니다. 
		     
		     $\theta_{mle}=\frac{N_{1}}{N_{0}+N_{1}}$
		    여기서 $N_1$​은 1의 개수(앞면), $N_0​$은 0의 개수(뒷면), $N$은 전체 샘플 수입니다.
		- **해석:** MLE는 단순히 앞면의 경험적 비율로 계산됩니다.
	- #### categorical 분포에 대한 MLE
		  
		- **범주 분포:** K면체 주사위를 N번 던질 때의 결과를 나타내는 확률변수 $Y_n​$을 고려합니다. 각각의 범주 $k$에 대한 확률은 $\theta_{k}$입니다.
		- **NLL 및 MLE 계산:** 범주 분포에 대한 NLL을 정의하고, MLE를 구하기 위해 Lagrange multipliers를 사용합니다. 
			- **Lagrange multipliers** (라그랑주 승수)
				  MLE에서 Lagrange Multipliers를 사용하는 예시 중 하나는 모수에 대한 제한 조건이 있는 경우입니다.
				- 예제
					목적 함수 $f$ 와 등식 제한조건 $g$ 이 다음과 같은 경우를 생각하자.
					$f\left(x,\ y\right)=x^2+y^2$
					$g\left(x,\ y\right)=x+y=1$
					
					이를 만족하는 f의 최적해(최대 or 최솟값)를 찾아라.
					
					라그랑주 승수법의 보조함수를 아래와 같이 정의합니다.
					$L\left(x,\ y,\ λ\right)=x^2+y^2-λ\left(x+y-1\right)$
					
					위의 함수 L의 gradient vector가 0벡터인 위치를 구합니다.
					$\frac{\partial L}{\partial x}=2x-λ=0$
					$\frac{\partial L}{\partial y}=2y-λ=0$
					$\frac{\partial L}{\partial λ}=x+y-1=0$
					
					위의 연립방정식을 풀면 다음과 같은 최적해의 위치를 구할 수 있습니다.
					$x=y=\frac{1}{2},\ λ=1$
				
			$\theta_{mle, k}=\frac{N_{k}}{N}$
			여기서 $N_{k}$​는 $Y=k$인 경우의 개수이고, $N$은 전체 샘플 수입니다.
		- **해석:** 각 범주의 경험적 비율로 MLE를 계산합니다.
	- #### univariate Gaussian 분포에 대한 MLE
		 - **단변량 가우시안 분포의 MLE:**  단변량 가우시안에서는 평균과 분산을 계산합니다.
			$\mu_{mle}=\frac{1}{N}\sum_{n-1}^{N}{y_{n}}$
			$\sigma_{mle}^{2}=\frac{1}{N}\sum_{n=1}^{N}(y_{n}-\mu_{mle})^{2}$
		
	- #### multivariate Gaussian 분포에 대한 MLE
		- **다변량 가우시안 분포의 MLE:** 다변량 가우시안에서는 평균 벡터와 공분산 행렬을 계산합니다.
			$\mu_{mle}=\frac{1}{N}\sum_{n-1}^{N}{y_{n}}$
			$\Sigma_{mle}=\frac{1}{N}\sum_{n=1}^{N}(y_{n}-\mu_{mle})(y_{n}-\mu_{mle})^{T}$
			
		- **해석:** 여러 변수가 상호 작용하는 경우, 각 변수 간의 공분산도 중요하게 작용합니다. 따라서 평균 벡터와 공분산 행렬을 사용하여 다변량 분포를 묘사합니다. 이것은 변수들 간의 상관관계 및 분산-공분산 특성을 고려하는 더 복잡한 분포를 나타냅니다.
	- #### linear regression 분포에 대한 MLE
		- **선형 회귀의 RSS 및 MLE 계산:**
			$RSS(w)=(Xw-y)^{T}(Xw-y)$
			$w_{mle}=(X^{T}X)^{-1}X^{T}y$
		- **해석:**
			RSS는 잔차 제곱합으로, 회귀 모델의 적합도를 나타냅니다.
			MLE는 선형 회귀에서는 $w$를 추정하여 주어진 데이터에 가장 확률적으로 적합한 회귀 모델을 찾습니다. 역행렬 계산을 통해 이를 수행할 입력과 출력 간의 관계를 최적화합니다.
		
## Empirical Risk Minimization (ERM)
- **정의:** MLE를 일반화하여 어떤 다른 손실 함수를 사용할 수 있도록 하는 개념
- ### Example
	 0-1 손실 함수는 다음과 같이 정의됩니다.
	 
	 $l_{01}(y_{n},\theta;x_{n})=\begin{cases}0,\;if\;y_{n}=f(x_{n};\theta)\\1,\;if\;y_{n}\ne f(x_{n};\theta)\end{cases}$
	 여기서 $f(x;\theta)$는 예측기입니다. 
	 이는 데이터 포인트가 올바른 범주에 할당되면 0이고, 그렇지 않으면 1입니다. 이러한 0-1 손실을 사용하여 에측 모델을 최적화하면 훈련 데이터셋에서의 미스클래스피케이션 비율을 최소화하는 것이 됩니다.
	 이때, 경험적 위험(Empirical risk)는 다음과 같이 표현됩니다.
	 
	 $L(\theta)=\frac{1}{N}\sum_{n=1}^{N}{l_{01}(y_{n},\theta;x_{n})}$
	 이것은 훈련 세트에서의 경험적 미스클래스피케이션 비율을 나타냅니다.
	 
- ### Surrogate loss
	  0-1 손실은 비선형 및 미분 불가능한 특성을 가지고 있어 최적화가 어려울 수 있습니다. 이를 극복하기 위해 대체 손실 함수를 사용합니다. 대표적인 대체 손실 함수로는 log loss와 hinge loss가 있습니다.
		![[Pasted image 20240102034737.png|500]]
		이진 분류를 위한 다양한 손실 함수의 그림입니다. 가로축은 마진이고 세로축은 손실입니다.
		
	-  **Log Loss:**
		 확률적인 이진 분류 문제를 고려해보겠습니다. 모델이 만들어내는 Log odds(η)를 사용하여 다음과 같이 확률을 정의할 수 있습니다: 
		
		$p(\tilde{y}|x,\theta)=\sigma(\tilde{y}​\eta)=\frac{1}{1+e^{-\tilde{y}\eta}}​$
		여기서 $σ$는 시그모이드 함수이며, $η=f(x;θ)$는 Log-odds입니다.
		
		로그 손실은 다음과 같이 정의됩니다: 
		
		$l_{ll}(\tilde{y},\eta)=log(1+e^{-\tilde{y}\eta})$
		이 손실 함수는 미스클래스피케이션 비율에 대한 최대한 타이트한 상한을 제공하며, 그림에서 그래프로 확인할 수 있습니다.
		
		- **Log-odds?**
			 오즈는 사건이 발생할 확률을 사건이 발생하지 않을 확률로 나눈 비율입니다.
			 이를 수식으로 나타내면 다음과 같습니다:
			 
			  $odds = \frac{p(y=1|x)}{1-p(y=1|x)}$
			  $p(y=1|x)$ 확률 값이 다음 그래프와 같이 1에 가까워질수록 odds 값은 엄청나게 상승합니다.
			   ![[Pasted image 20240102071736.png]]
			 - 한계점점
			 $0<odds<\infty$의 범위에 속하기에 , 범위에 제약이 있다.
			확률값과 odds값은 비대칭성(Asymmetric)을 띈다.
			   
			이러한 한계를 극복하기 위해 다음과 같이 로그함수를 취한다:
			
			$logit(p)=log\frac{p}{1-p}$
			이를 통해 $-\infty<log(odds)<\infty$의 범위를 가지며,
			대칭성 또한 가지게 된다.
			
			![[Pasted image 20240102072229.png]]
			
		
	
	- **Hinge Loss:**
		힌지 손실은 다음과 같이 정의됩니다:
		
		$l_{hinge​}(\tilde{y}​,\eta)=max(0,1-\tilde{y}\eta)$​ 
		힌지 손실은 0-1 손실의 볼록한 상한(Convex upper bound)을 제공하지만, 미분가능하지 않은 부분이 있습니다.
		
	 이러한 대체 손실 함수는 0-1 손실을 근사화하는 데 사용될 수 있으며, 그라디언트 기반 최적화를 통해 모델을 효과적으로 학습할 수 있도록 도와줍니다.

## Other Estimation Methods
- ### The metod of moments
	- 모멘트 방법(Method of Moments, MOM)은 통계 분포의 매개변수를 추정하기 위한 최대우도추정(MLE)의 대안입니다. MOM은 분포의 이론적 모멘트를 경험적 모멘트에 대입하고 이로부터 얻은 연립 방정식을 푸는 방법입니다.
		- **모멘트란?**
			  확률 분포의 특성을 설명하기 위한 통계적인 개념 중 하나로, 모멘트는 데이터 집합의 각 원소를 사용하여 계산되는 측도입니다. 모멘트는 분포의 형태와 특징을 파악하는 데 사용됩니다. n차 모멘트는 확률 변수의 n승을 사용하여 계산됩니다.
			  
		이론적 모멘트($\mu_{k}$)는 랜덤 변수 Y의 특정 함수들의 기대값을 나타냅니다. 예를 들어, $\mu1 = E[Y], \mu2 = E[Y^2]$ 등입니다. 경험적 모멘트는 데이터에서 추정되며 $\mu^k$로 표기됩니다. 
		이론적 모멘트와 경험적 모멘트는 다음과 같이 표현됩니다.
	    - 이론적 모멘트: $\mu_{k}​=E[Y^k]$
	    - 경험적 모멘트: $\mu^k=\frac{1}{N}​\sum_{n=1}{N}{​y_{n}^{k}}​$
		- 모멘트 방법 추정식: $\mu_k​=\mu^k$
	
		MOM 추정은 이론적 모멘트를 그들의 경험적 상응물에 대입하고 매개변수를 푸는 것을 포함합니다. MOM은 계산상 간단하지만 MLE만큼 효율적으로 데이터를 활용하지 못할 수 있으며 특정 경우에는 일관성 없는 결과를 초래할 수 있습니다.
		- **Why?**
			  해당 특징을 설명하는 모멘트를 선택하지 않으면 추정된 파라미터가 실제와 불일치할 수 있습니다. 또한 선택한 모멘트가 모집단에서 존재하지 않는 경우에도 불일치성이 발생할 수 있습니다.

- ### Online (recursive) estimation
	- 순차적으로 도착하는 데이터를 처리할 때 온라인 학습 또는 재귀 추정이 사용됩니다. 새로운 데이터 포인트가 이용 가능해짐에 따라 매개 변수 추정치를 업데이트하는 개념입니다. **재귀 업데이트**는 다음과 같은 형태를 가진다:
		  $\theta_t​=f(\hat{\theta}_{t−1}​,y_t​)$
		여기서 θt는 업데이트된 매개 변수, $\hat{\theta}_{t−1}$은 이전 추정치, $y_t$는 새로운 데이터 포인트입니다.
		
	- 지수 가중 이동 평균(EWMA): 온라인 학습에서 최근 예제에 더 많은 가중치를 부여하기 위해 지수 가중 이동 평균(EWMA)가 도입됩니다. 업데이트 규칙은 다음과 같다.
		  
		- $\hat{\mu}_{t} = \beta\mu_{t−1} + (1 -\beta)y_{t}$ = $\beta^2\mu_{t-2}+\beta(1-\beta)y_{t-1}+(1-\beta)y_{t}$
			- $\mu_t$는 현재 시점 $t$에서의 EWMA 추정치입니다.
			- $\mu_{t−1}$​은 이전 시점 $t−1$에서의 EWMA 추정치입니다.
			- $y_t$​는 현재 시점 $t$에서의 새로운 데이터 포인트입니다.
			
		- $(1-\beta)\sum_{k=0}^{t}{\beta^{k}}=(1-\beta)\frac{1-\beta^{t+1}}{1-\beta}=1-\beta^{t+1}$
		- $\tilde{\mu}_{t}=\frac{\hat{\mu}_{t}}{1-\beta^{t}}$
		여기서 0 < β < 1입니다. 따라서, 우리는 $\beta^{t+1} → 0$은 $t → \infty$이므로, β가 작을수록 과거를 더 빨리 잊고 최근 데이터에 보다 최근 데이터에 더 빠르게 적응합니다. 이는 그림에 설명되어 있습니다. 
		![[Pasted image 20240102065656.png]]
		1. **beta = 0.9인 경우:**
		    
		    - 빨간색 선은 일반적인 EWMA를 나타냅니다.
		    - 오렌지색 선은 편향 보정이 적용된 EWMA를 나타냅니다.
		    - EWMA는 현재 데이터 포인트에 대한 가중치를 높게 둔 채로 이전 데이터의 영향을 서서히 감소시키는 경향이 있습니다.
		    - 편향 보정된 EWMA는 초기에 특히 빨간색 선에 비해 작은 초기 편향을 가지며 점진적으로 증가합니다.
		2. **beta = 0.99인 경우:**
		    
		    - 빨간색 선은 일반적인 EWMA를 나타냅니다.
		    - 오렌지색 선은 편향 보정이 적용된 EWMA를 나타냅니다.
		    - 높은 $\beta$ 값은 현재 데이터 포인트에 대한 가중치를 훨씬 높게 두기 때문에 최신 데이터에 더 민감하게 반응합니다.
		    - 편향 보정된 EWMA는 초기에 상대적으로 큰 초기 편향을 가지며 더 빠르게 상승합니다.
		      
		이 규칙에 따라 EWMA는 이전 추정치와 새로운 데이터 포인트 간의 가중 평균을 계산하여 새로운 추정치를 얻습니다. 이 때, $\beta$값이 낮을수록 새로운 데이터에 대한 영향이 커지며, $\beta$ 값이 높을수록 이전 추정치의 영향이 큽니다.
		
		EWMA는 새로운 데이터에 대한 적응성과 추정치의 부드러움 사이의 균형을 제공합니다. $\beta$ 값에 따라 가중치가 조절되어 최신 데이터와 이전 데이터 간의 균형이 조절됩니다.
		편향 보정은 초기 편향을 완화하기 위해 도입되었으며, 초기에 편향이 크게 줄어들 수 있도록 합니다.

## Regularization
이 섹션에서는 기계 학습 모델에서 나타나는 과적합 문제를 해결하기 위한 정규화 기술에 대해 논의합니다. 과적합은 모델이 훈련 데이터에서는 잘 수행되지만 새로운, 보지 않은 데이터에는 일반화되지 않는 경우를 말합니다.

1. **MLE와 ERM의 기본 문제:**
    
    - 최대 우도 추정(MLE) 및 경험적 위험 최소화(ERM)은 훈련 세트에서 손실을 최소화하려고 시도하지만 이는 과적합으로 이어질 수 있습니다.
    - 과적합은 적은 관측을 기반으로 동전 던지기 결과를 예측하는 예제를 통해 설명됩니다.
	      
	    간단한 예로 동전 던지기를 생각해봅시다. 동전을 3번 던져서 3번 모두 앞면이 나왔다고 가정하면, MLE는 1이 됩니다. 하지만 이 모델을 사용하면 미래 동전 던지기 결과가 항상 앞면이 나올 것으로 예측할 것입니다. 이러한 문제는 모델이 훈련 데이터에 완벽하게 적합하여 경험적 분포를 완벽하게 따라갈 수 있지만, 대부분의 경우 경험적 분포가 실제 분포와 일치하지 않기 때문에 발생합니다.
2. **과적합 문제:**
    
    - 핵심 문제는 충분한 매개변수를 가진 모델이 훈련 데이터에 완벽하게 맞추려고 할 수 있지만 새로운 데이터에 대해 잘 일반화되지 않을 수 있다는 것입니다.
    - 정규화는 해결책으로 도입되며 음의 로그 우도 또는 경험적 위험에 패널티 항을 추가하는 것입니다.
3. **정규화된 목적 함수:**
    
    - 과적합 문제를 해결하기 위한 주요 방법 중 하나는 **정규화**(Regularization)를 사용하는 것입니다. 정규화는 음의 로그 우도 또는 경험적 위험에 패널티 항을 추가하여 목적 함수를 최적화하는 것을 의미합니다. 목적 함수는 다음과 같이 정의됩니다.
		
		$L(\theta;\lambda)=\frac{1}{N}\sum_{n=1}{N}{​ℓ(yn​,f(xn​;θ))}+λC(θ)$
		여기서 $λ$는 정규화 매개변수이고, $C(θ)$는 복잡성 페널티입니다.


## Bayesian Statistics
## Frequentist Statistics
## Reference
[Log-Odds](https://soobarkbar.tistory.com/12)
[EWMA](https://colab.research.google.com/github/probml/pyprobml/blob/master/notebooks/book1/04/ema_demo.ipynb)