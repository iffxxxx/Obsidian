## Introduction
확률 모델의 모든 매개변수 θ가 알려져 있다고 가정했습니다. 
이번 장에서는 데이터에서 이러한 매개변수를 학습하는 방법에 대해 설명합니다.
D로부터 θ를 추정하는 과정을 모델 피팅 또는 트레이닝이라고 하며, 머신 러닝의 핵심입니다.
이러한 추정치를 생성하는 방법에는 여러 가지가 있지만, 대부분은 다음과 같은 형태의 최적화 문제로 귀결됩니다.
$$\hat{\theta}=argmin\;L(\theta)$$
여기서 L(θ)는 일종의 손실 함수 또는 목적 함수입니다. 
이 장에서는 몇 가지 다른 손실함수에 대해 설명합니다.
### Maximum likelihood estimation(MLE)
- #### Definition
1. **정의 (식 4.2):**
    
    - MLE은 데이터셋 D에 대한 likelihood 함수 $p(D|\theta)$를 최대화하는 모수 $\theta$를 찾는 것으로 정의됩니다.
    - $\theta_{mle}=arg⁡max⁡_{\theta}\;p(D|\theta)$
2. **딥러닝에서의 추론:**
    
    - 딥러닝에서 "추론"은 "예측"으로 참조되며, 특정한 입력 x에 대한 출력 y의 확률 $p(y∣x,\hat{\theta})$를 계산하는 것을 의미합니다.
3. **독립 동일 분포 가정 (식 4.3):**
    
    - likelihood 함수는 각 예제의 독립성과 동일한 분포를 가정한 것으로 표현됩니다.
    
4. **로그 우도 (식 4.4):**
    
    - 로그 우도 �(�)L(θ)는 각 예제에 대한 로그 확률의 합으로 표현됩니다.
    - �(�)=∑�=1�log⁡�(��∣��,�)L(θ)=∑n=1N​logp(yn​∣xn​,θ)
5. **MLE 목적 함수 (식 4.5):**
    
    - MLE는 로그 우도를 최대화하는 것으로 정의되며, 최적화 문제로 표현됩니다:
        - �mle=arg⁡max⁡��(�)θmle​=argmaxθ​L(θ)
6. **음의 로그 우도 (NLL) (식 4.6):**
    
    - 최적화를 위해 (비용 함수를 최소화하기 위해) 음의 로그 우도가 일반적으로 사용됩니다.
    - NLL(�)=−∑�=1�log⁡�(��∣��,�)NLL(θ)=−∑n=1N​logp(yn​∣xn​,θ)
7. **무조건적 (비지도) MLE (식 4.7):**
    
    - 무조건적 (비지도) 모델의 경우, 출력 ��yn​은 있지만 입력 ��xn​이 없을 때 음의 로그 우도를 최소화하여 MLE를 찾습니다.
    - �mle=arg⁡min⁡�−∑�=1�log⁡�(��∣�)θmle​=argminθ​−∑n=1N​logp(yn​∣θ)
8. **입출력의 결합 우도:**
    
    - 어떤 경우에는 입력과 출력의 결합 우도를 최대화하고 싶을 수 있습니다.
    - �mle=arg⁡min⁡�−∑�=1�log⁡�(��,��∣�)θmle​=argminθ​−∑n=1N​logp(yn​,xn​∣θ)

요약하면, MLE는 통계 모델의 매개변수를 likelihood 함수를 최대화하여 추정하는 방법으로, 딥러닝에서는 입력을 주고 출력을 예측하는 작업에 사용됩니다. 음의 로그 우도는 일반적으로 최적화의 목적 함수로 사용되며, 조건부와 결합 우도는 모델링 작업에 따라 선택됩니다.