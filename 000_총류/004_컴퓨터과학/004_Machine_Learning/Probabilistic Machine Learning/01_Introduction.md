## What is machine learning
톰 미첼의 유명한 정의에 따르면 기계학습은 다음과 같습니다.
> "만약 컴퓨터 프로그램이 어떤 작업 T의 일부로서 경험 E로부터 배우며, 성능 측정 P에 대한 측정을 통해 경험 E에서 성능이 향상된다면, 그것은 경험 E에 대해 학습한다고 말합니다."

이 책에서는 일반적인 종류의 기계 학습을 확률적 관점에서 다룰 것입니다.
- 접근을 취하는 이유는 다음과 같습니다:
	1. 불확실성 하에서의 의사 결정에 최적의 접근 방법
	2. 확률적 모델링은 대부분의 과학 및 공학 분야에서 사용되는 언어

## Supervised learning
- **정의:** 가장 흔한 기계 학습 형태는 지도 학습입니다. 이 문제에서 작업 T는 입력 x ∈ X에서 출력 y ∈ Y로의 매핑 f를 학습하는 것입니다.
	
	경험 E은 학습 세트로 알려진 N개의 입력-출력 쌍 $D = {(x_n, y_n)}_{n=1}^{N}$로 제공됩니다. (N은 샘플 크기라고 불립니다.) 성능 측정 P는 예측하려는 출력 유형에 따라 다르며, 아래에서 논의합니다.
	
- ### Classification
	 분류 문제에서 출력 공간은 C개의 정렬되지 않은 상호 배타적인 레이블로 구성된 클래스 집합입니다. 이를 Y = {1, 2, . . . , C}와 같이 나타냅니다. 입력이 주어졌을 때 클래스 레이블을 예측하는 문제는 패턴 인식이라고도 합니다. (클래스가 두 개뿐인 경우 $y ∈ {0, 1}$ 또는 $y ∈ {−1, +1}$과 같이 나타내며, 이는 이진 분류라고 불립니다.)
	 
	 - #### Image classification
		  이미지 분류에서 입력 공간 X는 이미지의 집합으로 매우 고차원 공간입니다. 예를 들어, 색 이미지의 경우 C = 3 채널 (예: RGB) 및 D1 × D2 픽셀이면 X = R^D이고, 여기서 D = C × D1 × D2입니다. (실제로는 각 픽셀 강도를 일반적으로 {0, 1, ..., 255} 범위에서 정수로 표현하지만, 표기의 간결성을 위해 실수 값 입력을 가정합니다.) 이미지에서 레이블로의 매핑 f : X → Y를 학습하는 것은 상당히 어려울 수 있습니다. 
		  ![[Pasted image 20240103172815.png]]
		  다행히도 몇몇 식물학자들은 이미 세플 길이, 세플 폭, 꽃잎 길이, 꽃잎 폭과 같이 단순하지만 **매우 유용한 숫자 특성 4가지를 식별**해냈습니다. 이를 통해 세 가지 종류의 아이리스 꽃을 구별할 수 있습니다. 본 섹션에서는 간단함을 위해 이러한 훨씬 낮은 차원의 입력 공간 X = R^4를 사용할 것입니다. Iris 데이터 세트는 이러한 4가지 특성으로 설명되는 150개의 아이리스 꽃 예제 모음으로, 각 유형당 50개씩 있습니다. 이는 크기가 작고 이해하기 쉬워 예시로 자주 사용됩니다.
		
		특성의 작은 데이터 세트를 가질 때, 이를 N × D 행렬에 저장하는 것이 일반적이며, 각 행은 예제를 나타내고 각 열은 특성을 나타냅니다. 이를 설계 행렬이라고 합니다. 
		
	- #### Exploratory data analysis
		  ML 문제에 대처하기 전에, 일반적으로 탐색적 데이터 분석을 수행하는 것이 좋습니다. 이는 어떤 명백한 패턴이 있는지 확인하고(어떤 방법을 선택할 지에 대한 힌트를 제공할 수 있음) 데이터에 명백한 문제가 있는지(예: 레이블 노이즈 또는 이상치) 확인하는 데 도움이 됩니다.
		  ![[Pasted image 20240103173040.png]]
		  또한, 데이터를 더 잘 이해하기 위해 결정 트리(Decision Tree)나 다른 모델을 사용하여 시각화할 수 있습니다. 위의 그림은 Iris 데이터에 깊이가 2인 결정 트리를 적용한 예시입니다. 여기서 잎 노드는 예측된 클래스에 따라 색상이 부여되며, 각 상자 내에는 루트에서 해당 노드로 통과하는 훈련 샘플 수가 표시됩니다. 이를 통해 각 노드에 속한 각 클래스 값의 수를 알 수 있으며, 이 벡터를 정규화하여 각 노드에 대한 클래스 레이블 분포를 얻을 수 있습니다. 이를 통해 우리는 다수의 클래스를 선택할 수 있습니다.
		  
	- #### Expirical risk minimization
		 지도 학습의 목표는 분류 모델을 자동으로 생성하여 어떠한 입력에 대해서도 레이블을 신뢰성 있게 예측하는 것입니다. 이 작업의 성능을 측정하는 일반적인 방법은 훈련 세트에서의 오분류 비율을 기반으로 하는데, 이는 다음과 같이 정의됩니다:
		
		$L(\theta)=\frac{1}{N}\sum_{n=1}{N}​I(y_n​\ne f(x_n​;\theta))$
		
		여기서 $I(e)$는 이진 표시 함수로, 조건 $e$가 참일 때만 1을 반환하고 그렇지 않으면 0을 반환합니다. 즉,
		
		$I(e)=\begin{cases}1,\;if\;e\;is\;true\\0,\;if\;e\;is\;false\end{cases}$
	 
	- #### Uncertainty
		  우리는 입력과 출력 간의 매핑에 대한 지식 부족으로 인해(이를 '에피스템적 불확실성' 또는 '모델 불확실성'이라고 함) 또는 매핑에서 내재된(줄일 수 없는) 확률적 변동성으로 인해 정확한 출력을 완벽하게 예측할 수 없을 것입니다.
		  
		- **확인 방법:** 우리는 다음과 같은 조건부 확률 분포를 사용하여 불확실성을 캡처할 수 있습니다:
			$p(y=c|x;\theta)=f_c​(x;\theta)$
			
		- **제약:**$f_c​(x;\theta)$는 클래스 레이블 c의 확률을 반환하므로 각 c에 대해 $0≤f_c​≤1$ 및 $\sum_{c=1}^{C}​f_c​=1$이 필요합니다.
			  
		- **제약 해결방안:** 모델이 정규화되지 않은 로그-확률을 반환하도록 요구하는 것이 일반적입니다. 그런 다음 이를 소프트맥스 함수를 사용하여 확률로 변환할 수 있는데, 이는 다음과 같이 정의됩니다:
			  $softmax(a)=\bigg(\frac{e^{a_1}}{\sum_{c=1}^{1}e^{a_{c_{0}}}},\cdots,\frac{e^{a_C}}{\sum_{c=1}^{1}e^{a_{c_{0}}}}\bigg)$
			  
			이는 $R^C$를 $[0, 1]^C$로 매핑하며, $0≤softmax(a)_{c}​≤1$ 및 $\sum_{c=1}^{C}​softmax(a)_{c}​=1$ 제약을 충족시킵니다.
	
	- #### Maximum likelihood estimation
		  확률적 모델을 적합시킬 때, 일반적으로 손실 함수로 음의 로그 확률을 사용하는 것이 흔합니다:
		  
		$L(y,f(x;θ))=−logp(y∣f(x;θ))$
		
		이에 대한 이유는 직관적으로는 좋은 모델(낮은 손실)은 각 해당 입력 x에 대해 실제 출력 y에 높은 확률을 할당하는 모델입니다. 훈련 세트의 평균 음의 로그 확률은 다음과 같습니다:
		
		$NLL(θ)=−\frac{1}{N}​\sum_{n=1}{N}​log\,p(y_n​|f(x_n​;\theta))$
		
		이를 음의 로그 우도라고 합니다. 이를 최소화하면 최대 우도 추정치(MLE)를 계산할 수 있습니다:
		
		$\theta_{MLE}​=argmin_{\theta}\,​NLL(\theta)$
		
		이는 데이터에 모델을 맞추는 매우 일반적인 방법 중 하나입니다.
- ### Regression
	- **정의:** 회귀는 분류와 매우 유사합니다. 그러나 출력이 실수값이기 때문에 다른 손실 함수를 사용해야 합니다. 회귀에서 가장 일반적인 선택은 제곱 손실 또는 L2 손실을 사용하는 것입니다.
		  
		- **L2 Loss:** $L_2(y,\hat{y})=(y-\hat{y})^2$
			  이는 큰 잔차 $y-\hat{y}​$를 작은 것보다 더 크게 패널티를 부여합니다. 제곱 손실을 사용할 때의 경험적 위험은 평균 제곱 오차 또는 MSE와 동일합니다.
			
		- **MSE:** $MSE(\theta)=\frac{1}{N}\sum_{n=1}^{N}{(y_n-f(x_n;\theta))^{2}}$
		  
	- **출력문제:** 회귀문제에서 출력 분포가 가우시안 또는 정규 분포라고 가정하는 것이 일반적입니다.
		  $N(y∣μ,σ^2)=\frac{1}{2πσ^2​}​exp(−\frac{1}{2σ^2}​(y−μ)^2)$
		
		여기서 $\mu$는 평균, $σ^2$는 분산이며, $\sqrt{2πσ^2}$​는 밀도가 1이 되도록 하는 정규화 상수입니다. 회귀의 맥락에서는 평균을 입력에 따라 정의함으로써 다음 조건부 확률 분포를 얻을 수 있습니다.
		
		$NLL(\theta)=\frac{1}{2\sigma^{2}}MSE(\theta)+const$
		이를 NLL식에 대입할 경우 NLL은 MSE에 비례함을 볼 수 있습니다. 따라서 최대 우도 추정치를 계산하면 제곱 오차를 최소화하게 됩니다.
	- #### Linear reggression
		회귀 모델의 예로 Figure 1.5a의 1차원 데이터를 고려해 봅시다. 이 데이터는 다음과 같은 간단한 선형 회귀 모델로 적합시킬 수 있습니다.
		
		$f(x;\theta)=b+wx$
		![[Pasted image 20240103183840.png]]
		여기서 w는 기울기, b는 offset이며, $θ=(w,b)$는 모델의 모든 매개변수입니다. $\theta$를 조절하여 Figure 1.5b의 수직 선으로 표시된 제곱 오차의 합을 최소화할 수 있습니다. 최소 제곱 회귀의 목표는 다음과 같은 최소 제곱 솔루션을 찾는 것입니다.
		
		$\hat{\theta}=argminθ​MSE(θ)$
		
		다중 입력 특성이 있는 경우에는 다음과 같이 작성할 수 있습니다.
		
		$f(x;\theta)=b+w_{1}​x_{1}​+⋯+w_{D}​x_{D}​=b+w^{T}x$(1.24)
		
		여기서 θ=(w,b)입니다. 이것은 다중 선형 회귀라고 불립니다
	- #### Polynomial regression
		- **문제정의:** 
			![[Pasted image 20240103184240.png]]  
			선형 모델은 데이터에 대한 매우 좋지 않은 적합성을 보여줍니다. 
			
		- **해결방법:** 우리는 D 차수의 다항 회귀 모델을 사용하여 적합성을 향상시킬 수 있습니다. 이 모델은 다음과 같은 형태를 가지며, 여기서 $\phi(x)$는 입력에서 파생된 특성 벡터이며 다음과 같은 형태를 가집니다.
			
			$f(x;w)=w^{T}\phi(x)$
			
			$\phi(x)=[1,x,x2,\cdots,xD]$
			
			위의 그림의 예시를 통해 D = 2에서 더 나은 적합성이 나타나는 것을 확인할 수 있습니다. D를 증가시킬 수 있으며, 따라서 모델의 매개변수 수를 증가시킬 수 있습니다. 여기서 D = N - 1이면 데이터 포인트 당 하나의 매개변수가 있으므로 데이터를 완벽하게 보간할 수 있습니다.
	- #### Deep neural networks
		- **정의:** 다차원 다항 회귀 모델을 넘어서서 딥 뉴럴 네트워크(DNN)에 대한 소개가 이루어집니다. 다항식 확장을 통해 특성을 수동으로 변환했습니다. 이제 입력 특성에 대한 비선형 특징 추출을 자동으로 수행할 수 있는 강력한 모델을 만들어보겠습니다.
			
			이를 위해 입력 특성 추출기인 $\phi(x;w,V)$가 자체 세트의 매개변수 $V$를 가지도록 하고, 전체 모델은 다음과 같은 형식을 가지게 됩니다.
			
			$f(x;w,V)=w^T\phi(x;V)$
			
			이러한 방식으로 딥 뉴럴 네트워크는 여러 계층으로 구성된 모델로 표현됩니다. 각 계층은 간단한 함수들의 중첩으로 특징 추출기를 재귀적으로 분해합니다. 최종 계층은 선형 함수로 구성되며, 이렇게 구축된 DNN은 이미지에 대한 컨볼루션 신경망(CNN)이나 순차적인 데이터에 대한 순환 신경망(RNN)과 같은 변형이 포함될 수 있습니다.
- ### Overfitting and generalization
	- **Overfitting?:** 
		  적절하게 유연한 모델을 사용하면 (레이블 노이즈가 없다고 가정할 때) 각 입력에 대한 올바른 출력을 기억함으로써 훈련 손실을 0으로 만들 수 있습니다. 훈련 데이터에 완벽하게 맞지만 너무 복잡한 모델은 과적합이라고 합니다.
		  
	- **과적합 여부를 감지:**
		  하려면 (지금은) 훈련 세트를 생성하는 데 사용된 실제 (하지만 알려지지 않은) 분포 $p^∗(x,y)$에 접근할 수 있다고 가정해 봅시다. 그런 다음 경험적 위험 대신 이론적인 기대 손실 또는 모집단 위험을 계산합니다.
		  
	- **모델선택:**
		  우리가 훈련 세트를 사용하여 다양한 모델을 평가하면 항상 가장 복잡한 모델을 선택할 것입니다. 왜냐하면 그 모델이 최소 손실을 갖게되기 때문입니다. 따라서 테스트 손실이 최소가 되는 모델을 선택해야 합니다.
		
		실제로는 데이터를 훈련 세트, 테스트 세트 및 검증 세트로 나눠야 합니다. 검증 세트는 모델 선택에 사용되며 테스트 세트는 미래 성능 (모집단 위험)을 추정하는 데 사용됩니다. 즉, 테스트 세트는 모델 피팅이나 모델 선택에 사용되지 않습니다.
## Unsupervised learning
- **정의:**
	  지도 학습에서는 훈련 세트의 각 입력 예제 x에는 연관된 출력 대상 y가 있다고 가정하며, 목표는 입력-출력 매핑을 학습하는 것입니다. 이것은 유용하고 어려울 수 있지만, 지도 학습은 본질적으로 "높여진 곡선 피팅"이라고 할 수 있습니다.
	  
	아마도 훨씬 더 흥미로운 작업은 데이터를 "이해하려는" 것입니다. 즉, 우리는 관측된 "입력" $D = {xn : n = 1 : N}$만 가지고 있고 어떤 해당 "출력" yn도 없는 경우입니다. 이를 비지도 학습이라고 합니다. 확률적인 관점에서 비지도 학습의 작업은 새로운 데이터 x를 생성할 수 있는 p(x) 형태의 무조건적인 모델을 맞추는 것으로 볼 수 있습니다. 반면, 지도 학습은 입력이 주어졌을 때 (조건부로) 출력을 지정하는 p(y|x) 형태의 조건부 모델을 맞추는 것입니다.
	
	비지도 학습은 모델이 낮은 차원의 출력뿐만 아니라 고차원의 입력을 "설명"하도록 강요합니다. 이를 통해 "세계가 어떻게 작동하는지"에 대한 더 풍부한 모델을 학습할 수 있습니다.
- ### Clustering
	- **목표:**
		"유사한" 포인트를 포함하는 영역으로 입력을 분할하는 것입니다.
		
	- **방법:**
		1. 통계학계에서는 모델링되지 않은 외생 변수를 나타내기 위해 x를 사용하는 것이 일반적이지만, 단순히 입력으로 주어진 변수입니다.ㄴ 따라서 무조건적인 모델은 p(x)가 아닌 p(y)로 표시됩니다.
		2. 더 합리적인 접근은 "군중"의 주석자들에 의해 생성된 레이블에 대한 확률 분포를 포착하려는 것입니다. 이것은 작업 자체의 모호성으로 인해 특정 입력에 대해 여러 "올바른" 레이블이 있을 수 있음을 받아 들이는 것입니다.
		   
		   ![[Pasted image 20240104221405.png]]
		   
		   그림에서는 아이리스 데이터셋의 꽃잎 특징의 산점도를 보여줍니다. a에서는 어떤 클래스 레이블도 없는 포인트를 보여줍니다. 직관적으로 데이터에는 적어도 두 개의 클러스터가 있을 것으로 예상됩니다. 하나는 왼쪽 하단에 있고 다른 하나는 오른쪽 상단에 있습니다. 더 나아가 "좋은" 클러스터 집합은 상당히 조밀해야 한다고 가정한다면, 오른쪽 상단을 (적어도) 두 개의 하위 클러스터로 나누고 싶을 것입니다. 결과적으로 세 개의 클러스터로 나눈 결과는 b에 표시되어 있습니다. (클러스터의 올바른 수는 없습니다. 대신, 모델 복잡성과 데이터에 대한 적합성 사이의 균형을 고려해야 합니다.
- ### Discovering latent "factors of variation"
	- **정의:**
		고차원 데이터를 낮은 차원으로 축소하는 방법 중 하나로 잠재적인 "변이 요인"을 발견하는 개념을 다루고 있습니다. 이를 위해 각 고차원 출력이 일련의 잠재적인 낮은 차원 요소에 의해 생성된다고 가정합니다. 이를 다이어그램으로 나타내면 $z_n → x_n$으로 나타낼 수 있으며, 여기서 $z_n$은 숨겨진 요소이고 $x_n$은 관찰된 데이터입니다.
		
	- **FA모델:**
		  기본적으로는 각 잠재적인 요소 zn이 가우시안과 같은 간단한 확률 모델을 따르는 것으로 가정합니다. 가우시안이라면 각 요소가 무작위 K차원 벡터인 것으로 간주됩니다. 선형 모델을 사용하는 경우, $p(x_n|z_n; θ) = N (x_n|Wz_n + µ, Σ)$로 표현할 수 있으며, 이를 통해 Factor Analysis (FA)라는 모델을 얻을 수 있습니다.
		  
	- **성능:**
		  데이터의 본질적인 특성을 나타내는 낮은 차원 하위 공간을 찾을 수 있습니다. 더 나아가, 선형 모델을 사용하는 것을 넘어서 비선형 확장도 가능하며, 이를 통해 복잡한 데이터 구조를 더 잘 모델링할 수 있습니다.
- ### Self-supervised learning
	- **정의:**
		  최근에 인기를 얻은 비지도 학습 방법 중 하나는 자기 지도 학습이라고 알려져 있습니다. 이 접근 방식에서는 레이블이 지정되지 않은 데이터에서 대리 지도 학습 작업을 만듭니다. 
		  
		예를 들어, 색이 있는 이미지를 회색조 이미지로부터 예측하거나 문장에서 단어를 가리고 주변 문맥을 고려하여 그 단어를 예측하려고 시도할 수 있습니다. 여기서 기대하는 바는 결과 예측자 $\hat{x}_{1} = f(x_2; θ)$이며, 여기서 $x_2$는 관찰된 입력이고 $\hat{x}_{1}$은 예측된 출력입니다. 이 예측자가 데이터로부터 유용한 기능을 학습하여 표준 하류 지도 학습 작업에서 사용될 수 있기를 희망합니다. 이는 관찰된 데이터 뒤의 "진정한 잠재 요소" $z$를 추론하려는 어려운 문제를 피하고 대신에 표준 지도 학습 방법에 의존합니다.  
- ### Evaluationg unsupervised learning
	- **문제상황:**
		  비지도 학습 방법의 결과물의 품질을 평가하는 것은 매우 어렵습니다. 왜냐하면 비교할 대상이 없기 때문입니다.
		  
	- **일반적인 접근법:**
		  모델이 보이지 않은 테스트 예제에 할당한 확률을 측정하는 것입니다. 이를 위해 데이터의 (무조건적인) 음의 로그 우도를 계산하여 수행할 수 있습니다
		  
		이는 비지도 학습 문제를 확률 밀도 추정의 문제로 취급합니다. 이 방법의 아이디어는 좋은 모델은 실제 데이터 샘플에 대해 "놀랍지 않을" 것이라는 것입니다 (다시 말해, 높은 확률을 할당할 것입니다). 또한, 확률은 1.0이 되어야 하므로 모델이 데이터 샘플이 주로 나오는 데이터 공간의 영역에 높은 확률을 할당하면 데이터가 나오지 않는 영역에는 암시적으로 낮은 확률을 할당합니다. 따라서 모델은 데이터의 전형적인 패턴을 학습했습니다. 이는 데이터 압축 알고리즘 내에서 사용될 수 있습니다.
		
	- **제한사항:**
		  차원에서는 밀도 추정이 어렵습니다. 또한, 데이터에 높은 확률을 할당하는 모델이 유용한 고수준 패턴을 학습했다고해서 항상 그렇지 않을 수 있습니다 (모델은 결국 모든 훈련 예제를 기억할 수 있기 때문입니다).
		  
	- **해결방안:**
		  다른 평가 지표는 학습된 비지도 표현을 특징 또는 하류 지도 학습 방법의 입력으로 사용하는 것입니다. 비지도 방법이 유용한 패턴을 발견했다면, 이러한 패턴을 사용하여 원래의 특징을 사용할 때보다 훨씬 적은 레이블이 지정된 데이터를 사용하여 지도 학습을 수행할 수 있어야 합니다.
## Reinforcement learning
- **정의:**
	  지도 학습과 비지도 학습에 추가하여, 강화 학습이라고 불리는 세 번째 유형의 기계 학습이 있습니다. 강화 학습에서 시스템 또는 에이전트는 환경과 상호 작용하는 방법을 학습해야 합니다. 이는 정책 $a=π(x)$을 통해 인코딩될 수 있으며, 이 정책은 각 가능한 입력 x에 대해 어떤 동작을 수행할지를 지정합니다.
	  
- **지도학습과의 차이:**
	  지도 학습(SL)과의 차이점은 시스템이 어떤 동작이 최선인지(즉, 주어진 입력에 대해 생성해야 하는 출력) 알려주지 않는다는 것입니다. 대신, 시스템은 가끔씩만 보상(또는 처벌) 신호를 받습니다. 이는 감정 평가를 받는 비유로 설명할 수 있습니다. 비판가가 가끔씩 칭찬이나 극찬을 주면서 배우는 것과 유사합니다.
	  
- **구현의 어려움:**
	  주요 어려움 중 하나는 보상 신호가 가끔만 주어질 수 있으며(예: 에이전트가 최종적으로 원하는 상태에 도달하는 경우), 심지어 그때에도 에이전트가 어떤 동작이 보상을 받게 한 것인지 명확하지 않을 수 있습니다.
	  
- **해결방안:**
	  보상 신호에서 오는 정보의 최소한으로 보상하기 위해 다른 정보 원천을 사용하는 것이 일반적입니다. 이는 감독된 방식으로 사용될 수 있는 전문가 시연과 같은 다른 정보 원천을 포함합니다. 또는 비지도 학습 시스템이 환경의 기본 구조를 발견하는 데 사용될 수 있는 레이블이 없는 데이터입니다. 이를 통해 환경과의 상호 작용 횟수(환경과의 상호 작용)를 제한적으로 학습하는 것이 가능해집니다.
## Data
- **소개:**
	  모델링 및 알고리즘 측면에 중점을 두지만, 훈련 데이터의 특성과 품질도 학습된 모델의 성공에 중요한 역할을 합니다. 이 섹션에서는 이 책에서 사용할 몇 가지 일반적인 이미지 및 텍스트 데이터셋에 대해 간단히 설명합니다. 또한 데이터 전처리에 대한 주제를 간략히 논의합니다.
- ### Some common image datasets
	- #### Small image dataset
		- **정의:**
			  가장 간단하고 널리 사용되는 데이터셋 중 하나는 MNIST입니다. 이 데이터셋은 28 × 28 크기의 60,000개의 훈련 이미지와 10,000개의 테스트 이미지로 구성되어 있으며, 손글씨로 쓰인 10가지 카테고리의 숫자를 보여줍니다. 각 픽셀은 ${0, 1, . . . , 255}$ 범위의 정수이며, 일반적으로 $[0, 1]$로 재조정하여 픽셀 강도를 나타냅니다. 선택적으로 이를 이진 이미지로 변환할 수 있으며, 임계값 처리를 통해 수행할 수 있습니다.
			  ![[Pasted image 20240104234002.png]]
			- (a) MNIST 데이터셋의 시각화입니다. 각 이미지는 28 × 28 크기이며, 총 60,000개의 훈련 예제와 10,000개의 테스트 예제가 있습니다. 여기에서는 훈련 세트에서 처음 25개의 이미지를 보여줍니다.
			  
			- (b) EMNIST 데이터셋의 시각화입니다. 훈련 예제는 697,932개이며, 테스트 예제는 116,323개로 각 이미지는 28 × 28 크기입니다. 이 데이터셋은 총 62개의 클래스를 가지고 있으며 (a-z, A-Z, 0-9), 훈련 세트에서 처음 25개의 이미지를 보여줍니다.
			  
	- #### ImageNet
		- **문제상황:**
			  작은 데이터셋은 아이디어의 프로토타이핑에 유용하지만, 이미지 크기와 레이블이 지정된 예제 수 측면에서 더 큰 데이터셋에서도 메소드를 테스트하는 것이 중요합니다. 
			  
		- **해결방안:**
			  이러한 유형의 가장 널리 사용되는 데이터셋 중 하나는 ImageNet입니다. 이는 20,000개의 클래스에서 다양한 객체를 나타내는 대략 14백만 개의 256 × 256 × 3 크기 이미지로 구성된 데이터셋입니다.
			  
		- **효과:**
			  2015년은 CNN이 ImageNet의 이미지를 분류하는 작업에서 인간 (적어도 Andrej Karpathy와 같은 한 사람)을 능가할 수 있는 첫 해였습니다. 이는 CNN이 인간보다 뛰어난 비전 기술을 갖고 있다는 의미가 아닙니다. 대신, ImageNet 데이터셋은 "호랑이"와 "호랑이 고양이"와 같은 세부적인 분류를 많이 포함하고 있어서 인간들이 이해하기 어려운 것들이 많습니다. 반면 충분히 유연한 CNN은 임의의 패턴, 즉 무작위 레이블도 학습할 수 있습니다.
- ### Some common text datasets
	- #### Text classification
		  텍스트 분류는 간단한 NLP 작업 중 하나로, 이메일 스팸 분류, 감정 분석 (예: 영화 또는 제품 리뷰가 긍정적인지 부정적인지) 등에 사용될 수 있습니다.
		  
	- #### Machine translation
		더 어려운 NLP 작업 중 하나는 한 언어의 문장 x를 다른 언어의 "의미적으로 동등한" 문장 y로 매핑하는 것입니다. 이를 기계 번역이라고 합니다. 이러한 모델을 훈련시키려면 정렬된 (x, y) 쌍이 필요합니다. 다행히도 여러 이러한 데이터셋이 존재합니다.
		
	- #### Other seq2seq tasks
		  기계 번역의 일반화로 하나의 시퀀스 x에서 다른 어떤 시퀀스 y로의 매핑을 학습하는 것이 있습니다. 이를 seq2seq 모델이라고하며 이는 고차원 분류의 한 형태로 볼 수 있습니다(자세한 내용은 섹션 15.2.3 참조). 이 문제의 프레임은 매우 일반적이며 문서 요약, 질문 응답 등 다양한 작업을 포함합니다. 
		  ![[Pasted image 20240104235555.png]]
		예를 들어, 위의 표는 질문 응답을 seq2seq 문제로 정의하는 방법을 보여줍니다: SQuAD 데이터셋에서 샘플 단락의 질문-답변 쌍입니다. 각 답변은 단락에서의 텍스트 세그먼트입니다. 이는 문장 쌍 태깅을 사용하여 해결할 수 있습니다. 입력은 텍스트 T와 질문 Q이고 출력은 답변 A이며 이는 입력에서 추출된 단어의 집합일 수 있습니다.
		
	- #### Language modeling
		  "언어 모델링"이라는 rather grandiose한 용어는 텍스트 시퀀스 p(x1, . . . , xT)의 무조건적인 생성 모델링 작업을 나타냅니다. 이 작업은 어떠한 해당 "라벨" y 없이 입력 문장 x만 필요로 합니다. 따라서 이를 비지도 학습의 한 형태로 생각할 수 있으며, 언어 모델이 입력에 대한 출력을 생성하는 경우, seq2seq와 같이 이를 조건부 생성 모델로 간주할 수 있습니다.
- ### Preprocessing discrete input data
	- **소개:**
		  많은 기계 학습 모델은 데이터가 실수 값 특성 벡터, $x ∈ R^D$로 구성되어 있다고 가정합니다. 그러나 때로는 입력이 인종, 성별과 같은 범주형 변수 또는 어휘에서 가져온 단어와 같은 이산형 입력 특성을 가질 수 있습니다. 아래에서는 이러한 데이터를 벡터 형태로 변환하기 위한 몇 가지 전처리 방법에 대해 논의합니다.
		  
	- #### One-hot encoding
		- **정의:**
			범주형 특성을 가질 때 가중 조합을 계산할 수 있도록 이를 숫자 척도로 변환해야 합니다. 이러한 범주형 변수를 전처리하는 표준 방법은 원핫 인코딩 또는 더미 인코딩이라고 합니다.
			
		- **수식:**
			  변수 x가 K개의 값을 가진다면 해당 더미 인코딩은 다음과 같이 표시됩니다: $one-hot(x) = [I(x = 1), . . . ,I(x = K)]$. 예를 들어, 3가지 색이 있다면 (빨강, 녹색, 파랑), 해당 원핫 벡터는 $one-hot(red) = [1, 0, 0]$, $one-hot(green) = [0, 1, 0]$, 그리고 $one-hot(blue) = [0, 0, 1]$이 될 것입니다.
			  
	- #### Feature crosses
		- **문제상황:**
			더미 인코딩을 사용하는 선형 모델은 각 변수의 주 효과를 잡을 수 있지만 이들 간의 상호 작용 효과를 잡을 수는 없습니다. 예를 들어, 차량의 연료 효율성을 예측하려면 두 가지 범주형 입력 변수가 주어집니다: 유형(예: SUV, 트럭, 가족용 자동차)과 원산지(예: 미국 또는 일본). 삼항 및 이진 특성의 원핫 인코딩을 연결하면 다음과 같은 입력 인코딩이 생성됩니다: 
			$ϕ(x)=[1,I(x1​=S),I(x_1​=T),I(x_1​=F),I(x_2​=U),I(x_2​=J)]$
			
			여기서 $x_1$​은 유형이고 $x_2$​는 원산지입니다.
			
			이 모델은 피처 간의 의존성을 잡을 수 없습니다. 예를 들어, 트럭의 연료 효율성이 낮을 것으로 예상하지만 미국에서 오는 트럭이 일본에서 오는 트럭보다 더 낮을 수 있습니다. 이는 원산지의 기여가 자동차 유형과 독립적이기 때문에 방정식 (1.34)의 선형 모델을 사용하여 잡을 수 없습니다.
			
		- **해결방안:**
			  이를 해결하기 위해 명시적인 피처 교차를 계산할 수 있습니다. 예를 들어, 유형과 원산지의 상호 작용을 잡기 위해 새로운 합성 피처를 정의할 수 있습니다. 새로운 모델은 다음과 같이 됩니다: 
			 $$f(x;w)=w^Tϕ(x) =w_0​+w_1​I(x_1​=S)+w_2​I(x_1​=T)+w_3​I(x_1​=F)+w_4​I(x_2​=U)+w_5​I(x_2​=J)+w_6​I(x_1​=S,x_2​=U)+w_7​I(x_1​=T,x_2​=U)+w_8​I(x_1​=F,x_2​=U)+w_9​I(x_1​=S,x_2​=J)+w_{10}​I(x_1​=T,x_2​=J)+w_{11}​I(x_1​=F,x_2​=J)$$

			피처 교차의 사용으로 원래의 데이터셋이 많은 열을 가진 wide 형식으로 변환되는 것을 볼 수 있습니다.
- ### Preprocessing text data
	- **문제상황:**
		1. **가변 길이 문제**: 문서는 가변적인 길이를 가지고 있습니다. 이는 많은 모델들이 가정하는 고정 길이의 특성 벡터가 아닙니다. 이 문제를 해결하기 위해 텍스트를 특정 길이로 자르거나 패딩을 추가하는 등의 전략을 사용할 수 있습니다.
		    
		2. **카테고리 변수로서의 단어**: 단어는 많은 가능한 값을 가진 범주형 변수입니다. 이에 따라 해당하는 원핫 인코딩은 매우 고차원이며, 유사성의 자연스러운 개념이 없습니다. 이러한 문제를 해결하기 위해 워드 임베딩과 같은 기법을 사용하여 단어를 고차원 벡터로 표현할 수 있습니다.
		    
		3. **테스트 시 미처리 단어 (OOV 문제)**: 훈련 중에 보지 못한 단어가 테스트 시에 나타날 수 있습니다. 이를 해결하기 위해 훈련 데이터에 없는 단어에 대한 처리 방법을 정의해야 합니다. 이는 일반적으로 특별한 토큰으로 대체되거나, 특정 규칙에 따라 무시될 수 있습니다.
		   
	- #### Bag of Words (BoW)
		- **정의:**
			  가변 길이의 텍스트 문서를 처리하는 간단한 접근 방식 중 하나는 단어의 순서를 무시하고 단어들을 가방(bag)으로 간주하는 것입니다. 이를 위해 각 단어를 어휘(vocabulary)에서의 토큰으로 매핑합니다. 고정된 입력 공간의 벡터로 변환하려면 다음과 같은 전처리 단계를 거칩니다.
			  
		- **전처리 단계:**
			1. **단어 토큰화**: 문서의 각 단어를 어휘에서의 토큰으로 매핑합니다.
			2. **전처리 기법**: 문서의 토큰 수를 줄이기 위해 구두점 제거, 모든 단어를 소문자로 변환; "and" 및 "the"와 같은 흔하지만 정보를 제공하지 않는 단어 삭제 (불용어 제거); 단어를 기본 형태로 대체, 즉 "running" 및 "runs"를 "run"으로 대체 (어간 추출) 등의 다양한 전처리 기법을 사용합니다.
			   
		- **수식:**
- ### Handling missing data
## Discussion
- ### The relationship between ML and other fields
- ### Structure of the book
- ### Caveats

