## Handling_the_Question
- ### Problem
	- **TinyURL**은 긴 URL 단축 서비스이다.
		
		TinyURL에는 긴 URL을 입력할 수 있는 텍스트 박스가 존재한다. 여기에 URL을 입력하면, 서버는 이 주소를 받아 별도로 줄인 주소를 만들어 사용자에게 제공한다. (e.g. http://tinyurl.com/y9vdhh) 이미 다른 사람이 같은 URL로 TinyURL 서비스를 이용했다면, 서버는 중복 생성을 받아들이지 않고 원래 만들어져있던 주소를 알려준다.
		
- ### Solve
	1. **Broad Approach First:** 
		   문제에 처음 접할 때는 즉시 알고리즘 부분에 뛰어들거나 한 부분에 과도하게 집중하지 말고 먼저 전체적으로 접근하세요.
		   
		  `먼저, 이 URL 단축 서비스가 어떤 목적으로 사용될지 전체적으로 생각해봅시다. 사용자가 직접 짧은 URL을 만들 수 있을지, 아니면 자동으로 생성되어야 하는지에 대한 고민부터 시작해봅시다.`
	    
	2. **Use the Whiteboard:** 
		   화이트보드를 사용하면 인터뷰어가 당신이 제안하는 디자인을 따라갈 수 있습니다. 처음에 화이트보드에 올라가서 당신이 제안하는 것을 그림으로 표현하세요.
		   
		 `화이트보드에 가서 프론트엔드 서버, 백엔드 데이터 저장소, URL 생성기, 통계 처리기 등 주요 구성 요소를 그림으로 표현합니다. 사용자가 새 URL을 입력하면 어떤 일이 일어나는지 간략하게 설명하며 시스템의 전체적인 흐름을 제시합니다.`
	    
	3. **Acknowledge Interviewer Concerns:** 
		   인터뷰어는 걱정 사항을 나타낼 가능성이 높습니다. 이를 무시하지 말고 인정하세요. 인터뷰어가 지적한 문제를 인정하고 필요하면 변경하세요.
		   
		  `인터뷰어가 '사용자가 직접 URL을 만들면 어떻게 중복을 방지할 것인가?'라는 걱정을 표현하면, '그건 중요한 포인트입니다. 중복 방지를 위한 전략을 고려하고 구현할 수 있을 것입니다.'라고 답변합니다.`
	    
	4. **Be Careful About Assumptions:** 
		   잘못된 가정은 문제를 크게 바꿀 수 있습니다. 예를 들어, 시스템이 데이터 집합에 대한 분석/통계를 생성한다면 해당 분석이 완전히 최신이어야 하는지 여부는 중요합니다.
	    
		  `가정을 할 때, 'URL 통계가 실시간으로 업데이트되어야 하는가, 아니면 몇 분 지연이 허용되는가?'와 같은 중요한 가정을 명시하며 이에 따른 시스템의 특성을 고려합니다.`
		
	5. **State Your Assumptions Explicitly:** 
		   가정을 할 때는 명시적으로 언급하세요. 이렇게 하면 인터뷰어가 잘못된 경우 교정할 수 있고, 적어도 당신이 어떤 가정을 하고 있는지 알 수 있습니다.
		   
		  `인터뷰어에게 '저는 URL 통계는 10분 지연이 허용될 수 있다고 가정했습니다. 이에 대한 의견이나 수정이 필요한 부분이 있을까요?'와 같이 가정을 명시하고 인터뷰어의 피드백을 기다립니다.`
	    
	6. **Estimate When Necessary:** 
		   필요한 데이터가 없는 경우가 많습니다. 예를 들어, 웹 크롤러를 설계하는 경우 모든 URL을 저장하는 데 필요한 공간을 얼마나 예상할 수 있는지 추정해야 할 수 있습니다.
		   
		  `예를 들어, 하루에 최대 백만 개의 새 URL을 처리할 수 있다는 가정을 통해 데이터 저장소의 크기나 처리량 등을 대략적으로 추정합니다.`
	    
	7. **Drive:** 
		   지원자로서 당신은 주도권을 잡아야 합니다. 이는 인터뷰어와 대화하지 않는다는 것이 아니라, 오히려 질문하고 트레이드오프에 대해 솔직하게 얘기해야 한다는 것입니다. 질문을 하고 개선을 계속하며 깊이 들어가는 것이 중요합니다. 이러한 질문들은 궁극적인 디자인보다는 프로세스에 중점을 두고 있습니다.
		   
		  `인터뷰어와 소통하면서 질문을 주도적으로 제기하고, 시스템의 트레이드오프를 논의하며 지속적으로 디자인을 개선해 나갑니다. 최종적인 디자인보다는 프로세스에 중점을 두어 문제를 해결하는 방식을 강조합니다.`
## Design
이 글은 시스템 디자인 문제를 해결하기 위한 다섯 가지 단계에 대해 설명하고 있습니다. 예시로 "Design a Social Media Feed System"라는 시스템 디자인 문제를 다루는 과정을 각 단계에 따라 설명해보겠습니다.

1. **문제 범위 설정 (Step 1):** 
	   시스템을 디자인하기 전에 무엇을 디자인할지 정하는 것이 중요하다. 인터뷰어의 의도를 이해하고 필요한 기능이나 사용 사례를 나열해야 한다.
	   
	`우리는 소셜 미디어 피드 시스템을 디자인해야 합니다. 이 시스템은 사용자들에게 게시물을 보여주고 상호 작용할 수 있는 기능이 필요합니다. 필요한 기능으로는 포스트 작성, 댓글, 좋아요, 실시간 업데이트 등이 있을 것으로 예상됩니다.`
    
2. **합리적인 가정 설정 (Step 2):** 
	   필요한 경우 몇 가지 가정을 할 수 있지만, 이는 합리적이어야 한다. 이러한 가정은 디자인의 핵심 부분을 이해하고, 가정이 제품의 특성과 어떻게 관련되는지 인터뷰어와 논의해야 한다.
    
     `가정을 할 때, 하루에 약 1억 건의 활동이 발생할 것으로 예상하며, 사용자는 대부분 모바일 앱을 통해 접속할 것으로 가정합니다. 그리고 사용자가 피드를 스크롤할 때는 최신 게시물이 먼저 나오도록 하겠습니다.`
    
3. **주요 구성 요소 그리기 (Step 3):** 
	   화이트보드를 사용하여 주요 구성 요소의 다이어그램을 그린다. 시스템의 흐름을 끝에서 끝까지 설명하고, 간단하고 명백한 접근법으로 가정해본다.
	   
	`화이트보드에 가서 프론트엔드, 백엔드, 데이터베이스, 캐싱 시스템, 사용자 관리 등의 주요 구성 요소를 그림으로 표현합니다. 사용자가 피드를 요청하면 프론트엔드가 백엔드에 요청을 보내고, 백엔드에서는 데이터베이스에서 필요한 정보를 가져와 사용자에게 반환합니다.`
    
4. **주요 문제 식별 (Step 4):** 
	   디자인을 마련한 후 시스템에서 발생할 수 있는 주요 문제나 병목 현상을 찾는다. 예를 들어, 특정 상황에서의 성능 문제나 도전 과제를 고려한다.
	   
	 `피드 시스템에서의 주요 문제로는 사용자가 많아질 경우 대량의 데이터 처리, 실시간 업데이트의 복잡성, 알고리즘 효율성 등이 고려되어야 합니다. 또한, 게시물의 가시성과 관련하여 사용자의 선호도나 친구 관계도 고려해야 합니다.`
    
5. **주요 문제에 대한 재디자인 (Step 5):** 
	   주요 문제를 식별한 후 디자인을 조정한다. 큰 재디자인이 필요한 경우나 캐시 사용과 같은 작은 수정이 필요한 경우, 이를 업데이트하고 제한 사항에 대해 열려 말한다.
	   
	`주요 문제 중 하나로 실시간 업데이트의 복잡성이 있다면, 캐싱 시스템을 도입하여 사용자에게 최신 정보를 빠르게 제공할 수 있도록 할 것입니다. 또한, 사용자의 선호도를 고려해 알고리즘을 개선하고, 대량의 데이터 처리에는 적절한 데이터베이스 샤딩이나 인덱싱을 도입하여 성능을 향상시킬 것입니다.`

## Algorithms_that_Scale
이 글은 알고리즘이나 특정 기능을 확장 가능한 방식으로 디자인하는 방법에 대한 접근법을 단계별로 제시하고 있습니다. 일부 상황에서 전체 시스템을 디자인하는 대신 특정 기능이나 알고리즘을 확장 가능한 방식으로 설계해야 할 때 사용할 수 있는 방법입니다.

예시를 사용하여 "Design a Scalable Algorithm for Sorting Large Datasets"이라는 알고리즘 디자인 문제를 각 단계에 따라 설명하겠습니다.

- **단계 1: 질문하기**
	질문을 통해 문제를 정확히 이해하는 것이 중요합니다. 인터뷰어가 의도적으로 빠뜨린 세부 사항이 있을 수 있으며, 문제를 정확하게 이해하지 않으면 문제를 해결할 수 없습니다.
	
	 `데이터셋이 얼마나 큰지, 어떤 종류의 데이터가 있는지, 어떤 기준으로 정렬할지 등에 대한 추가 정보를 물어봅니다.`
	
- **단계 2: 가상의 상황 만들기**
	데이터가 모두 하나의 기계에 맞고 메모리 제한이 없다고 가정해봅니다. 문제를 어떻게 해결할 것인가요? 이 질문에 대한 답은 솔루션의 일반적인 개요를 제공할 것입니다.
	
	 `데이터가 모두 하나의 기계에 맞고 메모리 제한이 없다고 가정하면, 가장 간단하게는 퀵소트와 같은 효율적인 정렬 알고리즘을 사용할 수 있을 것입니다.`
	
- **단계 3: 현실로 돌아가기**
	이제 원래의 문제로 돌아가봅니다. 하나의 기계에 얼마나 많은 데이터가 들어갈 수 있고, 데이터를 어떻게 나눌지 등에 대해 고려해봅니다. 데이터를 논리적으로 어떻게 분할할지와 하나의 기계가 다른 데이터를 어디에서 찾아야 하는지 등이 일반적인 문제입니다.
	
	 `하지만 실제로는 대용량 데이터셋을 다루기 위해 여러 기계가 필요하고, 데이터를 나누고 분산시키는 방법이 필요합니다. 이때 데이터를 어떻게 논리적으로 분할할지, 각 기계가 어디에서 데이터를 찾아야 하는지 등을 고려합니다.`
	
- **단계 4: 문제 해결하기**
	마지막으로, 단계 2에서 식별한 문제를 해결하는 방법을 생각합니다. 각 문제의 해결책은 문제 자체를 완전히 제거하는 것일 수도 있고, 문제를 단순히 완화하는 것일 수도 있습니다. 일반적으로 단계 1에서 개요를 제시한 방법을 수정하여 계속 사용할 수 있지만 때로는 기본적인 방법을 근본적으로 변경해야 할 수도 있습니다.
    
     `각 데이터를 분산시키고 다시 병합하는 과정에서 발생하는 문제를 해결하기 위해 분산된 데이터를 효율적으로 정렬하는 방법을 고안합니다. 예를 들어, MapReduce와 같은 분산 프레임워크를 활용하여 정렬을 수행하고, 병합 단계에서 데이터 이동을 최소화합니다.`
    
	- **반복적인 접근:** 
		  문제를 해결한 후에도 새로운 문제가 발생할 수 있으므로 이를 해결해야 합니다. 반복적인 접근이 유용하며, 문제를 해결하는 데 있어서 자신의 솔루션에 문제를 찾아내는 것이 중요합니다.
		  
		 `이후 문제를 해결하면 새로운 문제가 나타날 수 있습니다. 예를 들어, 데이터의 분산이 불균형하게 되는 경우에 대한 문제 등을 고려하여 조정합니다.`
	    
	- **목표:** 
		  회사가 수백만 달러를 들여 복잡한 시스템을 설계한 것을 다시 설계하는 것이 목표가 아니라, 문제를 분석하고 해결할 수 있는 능력을 보여주려는 것입니다. 자신의 솔루션에 문제를 찾아내는 것은 이 능력을 강조하는 훌륭한 방법입니다.
		  
		 `절대적으로 완벽한 해결책은 없지만, 데이터를 효과적으로 분산시키고 정렬하는 방법을 제시하고, 이에 따른 문제를 인식하고 개선하는 능력을 보여줍니다.`
		 
## Key_Concepts
이 글에서는 시스템 디자인과 관련된 몇 가지 핵심 개념에 대해 간략한 소개를 제공하고 있습니다. 이러한 개념은 깊고 복잡하며, 더 자세한 정보는 온라인 자료를 활용하시기를 권장합니다.

- ### 수평 스케일링 vs. 수직 스케일링:
	- [출처](https://shuu.tistory.com/47)
    ![[Pasted image 20240128184459.png]]
    - **수직 스케일링 (Scale Up):** 
		- 특정 노드의 자원을 증가시키는 것. 예를 들어, 서버에 추가 메모리를 추가하여 부하 변화를 처리 능력을 향상시킵니다.
	    - 스케일업 (Scale-up)은 기존의 하드웨어를 보다 높은 사양으로 업그레이드 하는 것을 말한다.
		- 예로 들자면 성능이나 용량 증설을 목적으로 하나의 서버에 디스크를 추가하거나 CPU나 메모리를 업그레이드 하는 것이다.
		- 이처럼 하나의 서버의 처리 능력을 향상시키기 때문에 수직 스케일링 (Vertical Scaling)이라고도 부른다.
    - **수평 스케일링 (Scale Out):** 
	    - 노드의 수를 증가시키는 것. 예를 들어, 추가 서버를 추가하여 하나의 서버에 대한 부하를 줄입니다. 수직 스케일링보다 어렵지만 더 확장 가능합니다.
	    - 스케일아웃 (Scale-out)은 서버 장비를 추가하여 확장하는 방식으로 기존 서버만으로 용량이나 성능의 한계에 도달하면 비슷한 사양의 서버를 연결해 추가된 서버 대수만큼 용량이 증가할 뿐만 아니라 워크로드를 분담해 성능을 높이는 병렬 컴퓨팅을 구현할 수 있다.
		- 이처럼 서버를 추가로 확장하기 때문에 수평 스케일링 (Horizontal Scaling)이라고도 부른다.
	- **장단점:**
		![[Pasted image 20240128184523.png]]

- ### Load_Balancer
	- [출처](https://aws.amazon.com/ko/what-is/load-balancing/)
    - **요약:**
	    확장 가능한 웹 사이트의 프론트엔드 부분은 일반적으로 로드 밸런서 뒤에 배치됩니다. 이는 시스템이 부하를 고르게 분산하여 하나의 서버가 충돌하여 전체 시스템이 다운되는 것을 방지합니다. 애플리케이션을 지원하는 리소스 풀 전체에 네트워크 트래픽을 균등하게 배포하는 방법입니다.
	      
      - **장점:**
	      로드 밸런싱은 애플리케이션 서버와 방문자 또는 클라이언트 간의 인터넷 트래픽을 지시하고 제어합니다. 결과적으로 애플리케이션의 가용성, 확장성, 보안 및 성능이 향상됩니다.
	      
- ### Database_Denormalization_and_NoSQL
    - **데이터베이스 정규화:**  [출처](https://velog.io/@bsjp400/Database-DB-%EC%A0%95%EA%B7%9C%ED%99%94-%EB%B9%84%EC%A0%95%EA%B7%9C%ED%99%94%EB%9E%80)
	    - **NF?**  [출처](https://rebro.kr/160)
	    - **요약:**
		    SQL과 같은 관계형 데이터베이스에서의 조인은 시스템이 커질수록 느려질 수 있습니다. 이를 피하기 위해 불필요한 정보를 데이터베이스에 추가하여 읽기 속도를 향상시키는 것입니다.
		    
		- **목적:**
			- 불필요한  데이터를 제거, 중복 최소화
			- 데이터베이스 구조 확장 시 재디자인을 최소화
			- 다양한 관점에서의 query를 지원하기 위함
			- 무결성 제약조건의 시행을 간단하게 하기 위함
				  무결성 제약조건: 정확성, 일관성을 보장하기 위해 저장, 삭제, 수정 등을 제약하는 조건
			- 각종 이상 현상(Anomaly)을 방지하기 위함
			  
		- **단점:** 
			조인 연산이 많이 필요한 경우 성능 문제가 발생할 수 있습니다.
			
    - **NoSQL 데이터베이스:**  [출처](https://aws.amazon.com/ko/nosql/)
	    - **요약:**
		      조인을 지원하지 않고 데이터를 다르게 구조화할 수 있는 데이터베이스로, 확장 가능성이 뛰어납니다. 대규모 데이터를 다루거나 빠르게 쓰기 및 읽기가 필요한 경우에 유용합니다.
		      
		- **작동방식:**
			  NoSQL 데이터베이스에서는 데이터의 액세스 및 관리를 위해 다양한 데이터 모델을 사용합니다. 이러한 데이터베이스 유형은 유연한 데이터 모델, 큰 데이터 볼륨, 짧은 지연 시간이 필요한 애플리케이션에 최적화되었으며, 이 최적화는 관계형 데이터베이스의 데이터 일관성 제약 일부를 완화함으로써 달성됩니다. 스키마가 유연하며, 데이터베이스의 종류에 따라 다양한 모델을 사용할 수 있습니다. 키-값 저장소, 문서 지향 데이터베이스, 그래프 데이터베이스 등이 있습니다.
			  
			- **스키마?**
				데이터베이스를 구성하는 레코드의 크기, 키(key)의 정의, 레코드와 레코드의 관계, 검색 방법 등을 정의한 것. 데이터베이스를 구성하는 데이터 개체(entity), 속성(Attribute), 관계(Relationship) 및 데이터 조작시 데이터 값들이 갖는 제약 조건 등에 관해 전반적으로 정의 합니다.
				
		- **단점:**
			 일관성이나 트랜잭션 처리에서는 관계형 데이터베이스보다 유연성이 떨어질 수 있습니다.
			 
	- **비교:**
		  연관성 측면에서 말하면, 일부 NoSQL 데이터베이스는 데이터 중복을 허용하고, 스키마가 유연하게 정의되므로 일부 경우에는 정규화된 데이터베이스보다 중복이 더 허용될 수 있습니다. 그러나 이것은 NoSQL의 특정 유형과 구현에 따라 다를 수 있습니다. 종종 NoSQL은 대용량 및 분산 데이터 환경에서의 성능 및 확장성 요구를 충족시키는 데 더 적합한 선택으로 간주됩니다.
		  
- ### Database Partitioning (Sharding)
	- **Partitioning?**
		 큰 Table이나 인덱스를 관리하기 쉬운 단위로 분리하는 방법을 의미합니다. 데이터를 여러 기계로 분할하면서 어떤 데이터가 어느 기계에 있는지 파악하는 방법을 유지하는 것입니다.
		 
    - **종류:** 
	    - **Horizental Partitioning:**  [출처](https://nesoy.github.io/articles/2018-02/Database-Partitioning)
		     ![[Pasted image 20240128223717.png]]
		     데이터의 개수를 기준으로 나누어 Partitioning한다.
		     데이터의 개수가 작아지고 따라서 index의 개수도 작아지게 된다. 성능 향상으로 이어진다.
		     
		     허나 단점으로 서버간의 연결과정이 많아진다.
		     데이터를 찾는 과정이 기존보다 복잡하기 때문에 latency가 증가하게 된다.
		     
		- **Vertical Partitioning:**
			![[Pasted image 20240128223927.png]]
			 테이블의 컬럼을 기준으로 나누어 Partitioning한다.
			 정규화하는 과정도 이와 비슷하다고 볼 수 있지만 이는 이미 정규화된 Data를 분리하는 과정
			 자주 사용하는 컬럼등을 분리시켜 성능을 향상시킬 수 있다.
			 
		- **Key-Based (or Hash-Based) Partitioning:**  [출처](https://aws.amazon.com/ko/what-is/database-sharding/)
			 해시 샤딩은 해시 함수라는 수학 공식을 사용하여 데이터베이스의 각 행에 샤드 키를 할당합니다. 해시 함수는 행에서 정보를 가져와 해시 값을 산출합니다. 애플리케이션은 이 해시 값을 샤드 키로 사용하고 해당하는 물리적 샤드에 정보를 저장합니다.
			 
			 ![[Pasted image 20240128225046.png]]
			소프트웨어 개발자는 해시 샤딩을 사용하여 데이터베이스의 정보를 여러 샤드 간에 고르게 분산할 수 있습니다. 예를 들어 이 소프트웨어는 고객 레코드를 대체 해시 값이 1과 2인 두 개의 샤드로 분리할 수 있습니다.
			
			- **장단점**
				 해시 샤딩은 물리적 샤드 간에 데이터를 고르게 분산하지만 정보의 의미에 따라 데이터베이스를 분할하지는 않습니다. 따라서 소프트웨어 개발자가 컴퓨팅 환경에 물리적 샤드를 더 추가할 때 해시 값을 재할당하는 데 어려움을 겪을 수 있습니다.
				 
		- **Directory-Based partitioning:**
			 디렉터리 샤딩은 조회 테이블을 사용하여 데이터베이스 정보를 해당하는 물리적 샤드와 매칭합니다. 조회 테이블은 데이터베이스 열을 샤드 키에 연결하는 스프레드시트의 테이블과 같습니다. 예를 들어 다음 다이어그램은 의류 색상에 대한 조회 테이블을 보여 줍니다.
			 
			 ![[Pasted image 20240128225411.png]]
			 애플리케이션은 데이터베이스에 의류 정보를 저장할 때 조회 테이블을 참조합니다. 옷이 파란색이면 애플리케이션은 해당 샤드에 정보를 저장합니다.
			 
			 - **장단점:**
				 소프트웨어 개발자가 디렉터리 샤딩을 사용하는 이유는 그 유연성 때문입니다. 각 샤드는 데이터베이스의 의미 있는 표현이며 범위에 의해 제한되지 않습니다. 하지만 조회 테이블에 잘못된 정보가 포함되어 있으면 디렉터리 샤딩이 실패합니다.
				 
- ### Caching
	- **요약:**
		 캐싱은 데이터를 빠르게 검색하고 제공하기 위해 메모리에 저장하는 기술로, 주로 응용 프로그램 레이어와 데이터 저장소 사이에 위치합니다. 일반적으로 캐시는 간단한 키-값 쌍으로 구성되어 있습니다.
	    
    - **인메모리 캐시:**  [출처](https://aws.amazon.com/ko/nosql/in-memory/)
	      인 메모리 캐시는 랜덤 액세스 메모리(RAM)를 사용하여 데이터를 저장합니다. 이 기술은 데이터 테이블을 외장 드라이브가 아니라 RAM에 직접 저장합니다. 
	      
	     특수한 데이터 구조를 사용하면 데이터 레코드를 인덱싱할 수 있습니다. 인덱스는 특정 행과 열에 대한 직접적인 포인터 역할을 합니다. 하지만 실제 물리적 데이터는 압축된 비관계형 형식입니다. 액세스 요청을 하면 데이터베이스는 인덱스를 사용하여 정확한 데이터 값으로 이동합니다. 저장된 데이터는 항상 바로 사용할 수 있는 형식으로 제공됩니다.
	     
- ### Asynchronous Processing & Queues
    1. **비동기 처리:**  [출처](https://yozm.wishket.com/magazine/detail/1982/)
	       ![[Pasted image 20240128230826.png]]
	    - **목적:** 느린 작업을 동기적으로 수행하지 않고, 백그라운드에서 병렬적으로 처리함으로써 응답 시간을 최적화합니다.
	    - **예시:** 사용자가 어떤 작업을 요청했을 때, 해당 작업이 완료되길 기다리지 않고 다른 작업을 수행할 수 있습니다.
		
	2. **큐(Queues):**
	    - **목적:** 비동기 작업을 조직화하고 순서대로 실행하기 위해 큐를 사용합니다.
	    - **예시:** 여러 작업이 큐에 추가되고, 시스템이 여유 시간에 큐에서 작업을 하나씩 꺼내어 처리합니다.
	      
	3. **미리 처리:**
	    - **목적:** 미리 처리는 사전에 비동기적으로 작업을 수행하여 필요한 데이터나 페이지를 미리 준비합니다.
	    - **예시:** 웹 포럼의 경우, 가장 인기 있는 게시물 및 댓글 수가 업데이트되는 작업이 큐에 추가될 수 있습니다. 이러한 작업이 미리 처리되면 사용자가 해당 페이지를 요청할 때 즉시 결과를 제공할 수 있습니다.
	      
	- **코드:** [[09.0_Sync_vs._Async]]
	      
- ### Networking Metrics
     위 글에서는 컨베이어 벨트를 통해 아래의 개념들을 비유했다.
     
    - **Bandwidth (대역폭):** 
	    단위 시간당 전송할 수 있는 최대 데이터 양.
	    주로 초당 비트(bps), 킬로비트(kbps), 메가비트(Mbps) 또는 기가비트(Gbps)로 표현됩니다.
	    
		- **비유:**
			  컨베이어 벨트의 최대 수용 물건 수
			
    - **Throughput (처리량):** 
	    실제로 전송되는 데이터 양.
		대역폭과 마찬가지로 비트(bps), 킬로비트(kbps), 메가비트(Mbps) 또는 기가비트(Gbps)로 측정됩니다.
		
		- **비유:**
			컨베이어 벨트에서 한 단위 시간에 전송되는 실제 물건의 수입니다.
			컨테이너 벨트 폭을 넓게 만들어 한번에 더 많은 물건을 전달할 수 있습니다.
			
    - **Latency (지연 시간):** 
	    데이터가 한쪽에서 다른 쪽으로 이동하는 데 걸리는 시간.
	    주로 밀리초(ms)로 측정됩니다.
	    
	    - **비유:**
		     컨베이어 벨트를 통과하는 물건이 한쪽에서 다른쪽으로 이동하는 데 걸리는 시간
		     컨베이어 벨트를 길게 만들거나 짧게 만들어 물건의 양을 조절할 수 있고 속도를 빠르게 하여 더 빨리 도착하게 할 수 있습니다.
		      
- ### MapReduce
    - [출처](https://12bme.tistory.com/154)
	1. **개요:**
	    ![[Pasted image 20240201205134.png]]
	    - **목적:** MapReduce는 분산 컴퓨팅 환경에서 대량의 데이터를 처리하고 분석하기 위해 설계되었습니다.
	    - **처리 모델:** 이는 계산 작업을 두 가지 주요 단계로 분해하는 과정으로 Map 단계와 Reduce 단계로 구성됩니다.
	2. **Map 단계:**
		![[Pasted image 20240201205503.png]]
		`map(in_key, in_value) ->(inter_key, inter_value) list`
	    - **기능:** Map 단계는 데이터 집합을 가져와 매핑 함수를 적용합니다.
	    - **출력:** 매핑 프로세스의 중간 결과를 나타내는 일련의 키-값 쌍을 출력합니다.
	    - **병렬 실행:** 매핑 함수의 여러 인스턴스가 동시에 다른 입력 데이터 부분에서 실행되어 병렬 처리를 가능하게 합니다.
	3. **셔플 및 정렬:**
	    
	    - Map 단계 이후 시스템은 키를 기반으로 중간 키-값 쌍을 조직하고 그룹화하기 위해 셔플 및 정렬 단계를 수행합니다. 이는 다음 단계를 위해 데이터를 준비하는 데 중요합니다.
	      중간 키와 연관되어 있는 모든 값은 같은 리듀서로 보내진다.
		
		  중간 키와 그 값들의 리스트들은 키 순서대로 정렬(해쉬값이 같은건 같은 리듀서)되어 리듀서로 보내진다.
		
		이 단계는 '셔플(Shuffle)과 정렬(Sort)'라고 알려져 있다. (Expensive한 과정)
	4. **Reduce 단계:**
	    
	    - **기능:** Reduce 단계는 Map 단계에서 생성된 키와 관련된 값 세트를 가져옵니다.
	    - **출력:** 값에 대해 축소 함수를 적용하여 최종 출력으로 새로운 키-값 쌍 세트를 생성합니다.
	    - **병렬 실행:** Map 단계와 마찬가지로 축소 함수의 여러 인스턴스가 동시에 실행되어 효율적인 병렬 처리를 제공합니다.
	5. **반복적인 프로세스:**
	    
	    - Reduce 단계의 결과는 MapReduce 프로그램으로 다시 피드백되어 매핑 및 축소의 추가 라운드를 위해 사용될 수 있습니다. 이 반복적인 프로세스는 원하는 계산 수준에 도달할 때까지 계속될 수 있습니다.
	6. **확장성:**
	    
	    - MapReduce는 클러스터 내의 계산을 분산시켜 대규모 데이터 세트를 효율적으로 처리할 수 있는 확장 가능한 솔루션을 제공합니다.
	7. **사용 예시:**
	    
	    - MapReduce는 로그 분석, 대규모 인덱싱, 데이터 변환 작업 등 다양한 데이터 처리 시나리오에서 흔히 사용됩니다.
	8. **MapReduce 프레임워크:**
	    
	    - Google이 개념을 소개했지만 Apache Hadoop과 같은 여러 오픈 소스 프레임워크가 MapReduce 프로그래밍 모델을 구현했습니다. 이러한 프레임워크는 MapReduce 응용 프로그램의 개발 및 배포를 단순화하는 도구와 라이브러리를 제공합니다.
## Considerations
1. **장애:**
    
    - **정의:** 시스템의 어떤 부분이든 장애가 발생할 수 있습니다. 하드웨어, 소프트웨어, 또는 네트워크 문제 등이 포함됩니다.
    - **계획:** 잠재적인 장애에 대비하고 처리하거나 완화하기 위한 전략을 수립하는 것이 중요합니다. 이는 중복성, 백업, 오류 처리 메커니즘 등을 포함할 수 있습니다.
2. **가용성 및 신뢰성:**
    
    - **가용성:** 시스템이 운영되고 사용자에게 접근 가능한 시간의 백분율을 나타냅니다. 높은 가용성은 다운타임이 적음을 의미합니다.
    - **신뢰성:** 일정 시간 단위로 시스템이 정상적으로 운영될 확률입니다.
    - **고려사항:** 높은 가용성 및 신뢰성을 위한 설계는 다운타임을 최소화하기 위한 조치를 채택하는 것을 포함합니다. 이는 로드 밸런싱 및 내결함 아키텍처와 같은 것을 의미할 수 있습니다.
3. **읽기 중심 vs. 쓰기 중심:**
    
    - **설계에 미치는 영향:** 응용 프로그램이 읽기 또는 쓰기 작업 중 어떤 것을 많이 수행하느냐에 따라 시스템 설계에 영향을 미칩니다.
    - **쓰기 중심:** 쓰기 작업이 많은 경우, 잠재적인 과부하와 장애 관리를 위해 쓰기를 대기열에 넣는 등의 고려사항이 있을 수 있습니다.
    - **읽기 중심:** 읽기가 많은 경우 성능을 향상시키기 위해 캐싱 메커니즘을 사용할 수 있습니다.
4. **보안:**
    
    - **중요성:** 보안 위협은 시스템에 심각한 영향을 미칠 수 있습니다. 미승인 액세스, 데이터 유출 또는 서비스 중단과 같은 문제를 고려해야 합니다.
    - **고려사항:** 보안을 고려한 설계는 잠재적인 취약점을 식별하고 암호화, 액세스 제어 및 정기적인 보안 감사 등을 구현하는 것을 포함합니다.
5. **트레이드오프:**
    
    - **면접에서의 개방성:** 시스템 설계에서 트레이드오프가 있다는 사실을 인정하는 것이 중요합니다. 예를 들어 성능을 최적화하는 것이 다른 측면(비용 또는 복잡성과 같은)에 미치는 영향을 생각해볼 수 있습니다.
    - **의사소통:** 면접에서는 후보자가 설계 결정의 이유, 선택한 설계 방식 및 관련된 트레이드오프에 대해 투명하게 의사소통하는 것이 중요합니다.
6. **"완벽한" 시스템은 없다:**
    
    - 어떤 시스템이건 TinyURL, Google Maps, 또는 다른 어떤 시스템이건 완벽한 디자인은 존재하지 않습니다.
    - **Trade-offs(트레이드오프):** 모든 시스템 디자인은 어떤 가정하에서는 훌륭하게 작동할 수 있지만, 다른 가정하에서는 그렇지 않을 수 있습니다.
    - **다양성:** 두 명의 사람이 동일한 시스템에 대해 서로 다른 디자인을 가질 수 있으며, 각각은 다른 전제 조건 하에서 훌륭한 디자인일 수 있습니다.
7. **문제 범위 및 사용 사례 이해:**
    
    - **목표:** 문제의 범위를 이해하고 사용 사례에 맞게 적절한 디자인을 수립하는 것이 중요합니다.
    - **합리적인 가정:** 특정 가정에 기반하여 디자인을 만들고, 그 가정을 기반으로 타당한 트레이드오프를 고려하는 것이 필요합니다.
8. **디자인의 한계 인정:**
    
    - **완벽한 것을 기대하지 않기:** 시스템 디자인에서 완벽한 솔루션을 기대하지 말아야 합니다.
    - **열린 의견 표명:** 디자인의 약점에 대해 솔직하게 인정하고, 이를 개선하거나 대응할 수 있는 전략을 고려해야 합니다.
## Example
- ### Problem
	주어진 문제는 수백만 개의 문서 중에서 특정 단어 목록을 포함하는 모든 문서를 찾는 방법에 대한 것입니다. 단어는 어떤 순서로든 나타날 수 있지만 완전한 단어여야 합니다. "book"과 "bookkeeper"는 일치하지 않아야 합니다.
	
	문제 해결을 시작하기 전에 우리는 이 findWords 프로시저가 한 번만 실행되는 것인지, 아니면 여러 번 호출되는 것인지를 이해해야 합니다. 여기서는 findWords를 동일한 문서 집합에 대해 여러 번 호출할 것으로 가정하고, 따라서 전처리의 부담을 감수할 수 있다고 가정합니다.
	
- ### Solve
	- **Step 1:** 
		첫 번째 단계는 몇 십 개의 문서만 있다고 가정할 때 findWords를 어떻게 구현할 것인지 고려하는 것입니다. 이 경우 각 문서를 전처리하고 해시 테이블 인덱스를 만드는 것이 하나의 방법입니다. 이 해시 테이블은 단어에서 해당 단어를 포함하는 문서 목록으로 매핑됩니다. 예를 들어,
		
		- "books" -> {doc2, doc3, doc6, doc8}
		- "many" -> {doc1, doc3, doc7, doc8, doc9}
		
		이제 "many books"를 검색하려면 "books"와 "many"에 대한 값의 교집합을 찾고 결과로 {doc3, doc8}을 반환합니다.
		
	- **Step 2:** 
		이제 원래의 문제로 돌아갑니다. 수백만 개의 문서가 있는 경우 어떤 문제가 발생할 수 있는지 살펴봅니다. 문서를 여러 대의 기계로 분할해야 할 필요가 있고, 가능한 단어 수 및 문서에서 단어의 반복과 같은 여러 요인에 따라 전체 해시 테이블을 한 대의 기계에 저장할 수 없을 수 있습니다.
		
		- **Dividing the Hash Table:** 해시 테이블을 어떻게 분할할 것인가?
		- **Processing Documents on Machines:** 문서를 처리하고 결과를 다른 기계로 전송하는 프로세스는 어떻게 보일까?
		- **Machine Lookup Table:** 어떻게 데이터를 소유한 기계를 알 수 있을까?
		
		이러한 세 가지 주요 고려사항이 도입됩니다.
		
	- **Step 3:**
		Step 3에서는 이러한 문제에 대한 해결책을 찾습니다. 한 가지 해결책은 단어를 알파벳순으로 키워드별로 나누어 각 기계가 단어 범위를 제어하도록 하는 것입니다 (예: "after"에서 "apple"까지).
		
		이 접근 방식에서는 키워드를 알파벳순으로 반복하면서 가능한 많은 데이터를 한 대의 기계에 저장합니다. 해당 기계가 가득 차면 다음 기계로 이동할 수 있습니다. 이 접근 방식의 이점은 조회 테이블이 작고 간단하다는 것입니다 (값의 범위만 지정하면 되기 때문). 그러나 단점은 새로운 문서나 단어가 추가되면 키워드를 비용이 많이 드는 방식으로 이동해야 할 수 있다는 것입니다.
	![[Pasted image 20240205213636.png]]
	문자열 목록과 일치하는 모든 문서를 찾으려면 먼저 목록을 정렬하고 각 기계에 속한 문자열에 대한 조회 요청을 보낼 수 있습니다. 예를 들어, 문자열이 "after builds boat amaze banana"인 경우, 기계 1에는 {"after", "amaze"}에 대한 조회 요청을 보냅니다. 기계 1은 "after" 및 "amaze"를 포함하는 문서를 조회하고 이 문서 목록의 교집합을 수행합니다. 기계 3도 {"banana", "boat", "builds"}에 대해 동일한 작업을 수행합니다.
	
	최종 단계에서는 초기 기계가 기계 1 및 기계 3의 결과에 대한 교집합을 수행합니다.